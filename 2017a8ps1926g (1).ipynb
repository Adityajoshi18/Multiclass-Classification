{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "gSK6l_dCOoEA",
    "outputId": "7b455b0f-a93d-4cee-ebb0-c9f28d6c571e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "DKD1zs97RdSD",
    "outputId": "6241e3ce-0acc-48bc-bbff-5004878f36ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.26166000108657</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.44296997784168</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8.31096867770419</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9.43591274696865</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.16976754958987</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Quantities Number of Insignificant Quantities    Size  \\\n",
       "ID                                                                   \n",
       "0                     2                                  0  Medium   \n",
       "1                     2                                  0  Medium   \n",
       "2                     2                                  0  Medium   \n",
       "3                     2                                  0       ?   \n",
       "4                     2                                  0  Medium   \n",
       "\n",
       "   Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                     \n",
       "0                     19                          68   \n",
       "1                     20                          66   \n",
       "2                     20                          87   \n",
       "3                     21                          73   \n",
       "4                     16                          53   \n",
       "\n",
       "   Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                  \n",
       "0                             3                    3            2   \n",
       "1                             3                    3            2   \n",
       "2                             3                    3            2   \n",
       "3                             3                    3            2   \n",
       "4                             3                    3            2   \n",
       "\n",
       "    Second Index        Difficulty  Score  Class  \n",
       "ID                                                \n",
       "0              7  1.26166000108657  133.0      0  \n",
       "1              7  1.44296997784168   59.0      3  \n",
       "2             10  8.31096867770419   79.0      0  \n",
       "3              8  9.43591274696865   43.0      0  \n",
       "4              7  1.16976754958987   18.0      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"/kaggle/input/bitsf312-lab1/train.csv\",encoding=\"utf-8\",index_col=0)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oRKJTiIY26r7",
    "outputId": "b7b6bf88-d0c3-41e0-de98-be3b5b3f9124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111\n",
       "5     81\n",
       "2     80\n",
       "4     44\n",
       "3     33\n",
       "1     22\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_Vgn1ZQH4fQx",
    "outputId": "0a41e047-589e-46aa-a5b6-95efc35d4294"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "for columns in data.columns:\n",
    "  data.drop( data[ data[columns] == \"?\" ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DXltGbwjoeCh",
    "outputId": "b8ae389f-5cf3-4f7a-accd-1e3c0e17d78d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medium', 'Small', 'Big'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "y7M3DqM_sTJC",
    "outputId": "5c33b51a-88fc-4884-ac72-2868beff3fcc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.26166000108657</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.44296997784168</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8.31096867770419</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.16976754958987</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.30438968541013</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Quantities Number of Insignificant Quantities  Size  \\\n",
       "ID                                                                 \n",
       "0                     2                                  0     1   \n",
       "1                     2                                  0     1   \n",
       "2                     2                                  0     1   \n",
       "4                     2                                  0     1   \n",
       "5                     2                                  0     1   \n",
       "\n",
       "   Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                     \n",
       "0                     19                          68   \n",
       "1                     20                          66   \n",
       "2                     20                          87   \n",
       "4                     16                          53   \n",
       "5                     18                          64   \n",
       "\n",
       "   Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                  \n",
       "0                             3                    3            2   \n",
       "1                             3                    3            2   \n",
       "2                             3                    3            2   \n",
       "4                             3                    3            2   \n",
       "5                             3                    3            2   \n",
       "\n",
       "    Second Index        Difficulty  Score  Class  \n",
       "ID                                                \n",
       "0              7  1.26166000108657  133.0      0  \n",
       "1              7  1.44296997784168   59.0      3  \n",
       "2             10  8.31096867770419   79.0      0  \n",
       "4              7  1.16976754958987   18.0      4  \n",
       "5              7  1.30438968541013   77.0      4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "data['Size'] = data['Size'].map({\n",
    "    'Small': 0, \n",
    "    'Medium': 1,\n",
    "    'Big':2\n",
    "    })\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pYNzsfKLSlA5",
    "outputId": "5bb41e3b-bdfe-494c-e408-e6d430ea9e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDs8EcaFZ5u2"
   },
   "outputs": [],
   "source": [
    "x_train = data.iloc[:,:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATRVFWTBbb1l"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_train = data.iloc[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m5bITdGAbnWS",
    "outputId": "703251ca-88b2-4bd2-9efe-c84d8b1d4f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jmBqKy2Vs9FA",
    "outputId": "327b0753-098f-4639-a04a-f4e0e9844cf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xUcdLHSE30fY",
    "outputId": "327afae5-3c3d-42e4-d347-f813953a0e7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[\"Size\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dri5KGiy0sSE",
    "outputId": "e104c4e4-a333-4eaa-85c1-74a414865120"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 2, 5, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRPbq83U1Rvj"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_train_enc = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "TcZPDiOY1eCC",
    "outputId": "07eb42e8-00ff-455d-9d25-c89abfc139af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "Ha_60ML21lFi",
    "outputId": "6f61ae48-f45d-4183-c062-66daed36af6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0      0\n",
       "1      3\n",
       "2      0\n",
       "4      4\n",
       "5      4\n",
       "      ..\n",
       "366    2\n",
       "367    0\n",
       "368    2\n",
       "369    5\n",
       "370    0\n",
       "Name: Class, Length: 356, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "mBpSRVDOtAeA",
    "outputId": "dbfdc906-1533-472d-c1e4-c705609dca6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.26166000108657</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.44296997784168</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8.31096867770419</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.16976754958987</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.30438968541013</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Quantities Number of Insignificant Quantities  Size  \\\n",
       "ID                                                                 \n",
       "0                     2                                  0     1   \n",
       "1                     2                                  0     1   \n",
       "2                     2                                  0     1   \n",
       "4                     2                                  0     1   \n",
       "5                     2                                  0     1   \n",
       "\n",
       "   Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                     \n",
       "0                     19                          68   \n",
       "1                     20                          66   \n",
       "2                     20                          87   \n",
       "4                     16                          53   \n",
       "5                     18                          64   \n",
       "\n",
       "   Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                  \n",
       "0                             3                    3            2   \n",
       "1                             3                    3            2   \n",
       "2                             3                    3            2   \n",
       "4                             3                    3            2   \n",
       "5                             3                    3            2   \n",
       "\n",
       "    Second Index        Difficulty  Score  \n",
       "ID                                         \n",
       "0              7  1.26166000108657  133.0  \n",
       "1              7  1.44296997784168   59.0  \n",
       "2             10  8.31096867770419   79.0  \n",
       "4              7  1.16976754958987   18.0  \n",
       "5              7  1.30438968541013   77.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "yeBFCJQXtEtP",
    "outputId": "7c20fb25-8bbc-4aa7-b3bb-18d96463ac64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356 entries, 0 to 370\n",
      "Data columns (total 11 columns):\n",
      "Number of Quantities                  356 non-null object\n",
      "Number of Insignificant Quantities    356 non-null object\n",
      "Size                                  356 non-null int64\n",
      "Total Number of Words                 356 non-null object\n",
      "Total Number of Characters            356 non-null int64\n",
      "Number of Special Characters          356 non-null object\n",
      "Number of Sentences                   356 non-null int64\n",
      "First Index                           356 non-null int64\n",
      "Second Index                          356 non-null int64\n",
      "Difficulty                            356 non-null object\n",
      "Score                                 356 non-null float64\n",
      "dtypes: float64(1), int64(5), object(5)\n",
      "memory usage: 33.4+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byLieIpVWUB7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(32,input_dim=11, activation='relu'))\n",
    "  model.add(Dense(16, activation='relu'))\n",
    "  model.add(Dropout(rate=0.2))\n",
    "  model.add(Dense(8, activation='relu'))\n",
    "  model.add(Dropout(rate=0.2))\n",
    "  model.add(Dense(6,activation='softmax'))\n",
    "  \n",
    "\n",
    "  # Compile \n",
    "  adam = Adam(lr=10**-3)\n",
    "  model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  print(model.summary())\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bdu3eGiWhkw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_train(X_train, Y_train, n_folds, iterr, bsize):\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=7)\n",
    "    hist = []\n",
    "    val_hist=[]\n",
    "    acc=[]\n",
    "    val_acc=[]\n",
    "    for train, test in kfold.split(X_train, Y_train):\n",
    "        #----------------Build NN model--------\n",
    "        new_model = create_model()\n",
    "        #----------------Fit the model-----------------\n",
    "        xtr = X_train.iloc[train]\n",
    "        ytr = Y_train[train]\n",
    "        xval = X_train.iloc[test]\n",
    "        yval = Y_train[test]\n",
    "    \n",
    "        \n",
    "        history = new_model.fit(xtr, ytr,validation_data=(xval, yval), epochs=iterr, batch_size=bsize, verbose=1)\n",
    "        hist.append(history.history['loss'])\n",
    "        val_hist.append(history.history['val_loss'])\n",
    "        acc.append(history.history['accuracy'])\n",
    "        val_acc.append(history.history['val_accuracy'])\n",
    "        plt.figure()\n",
    "        plt.plot(history.history['loss'], label = \"Training Loss\")\n",
    "        plt.plot(history.history['val_loss'], label = \"Validation loss\")\n",
    "        plt.xlabel('Number of epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    mean_val_hist = np.mean(val_hist,axis=0)\n",
    "    main_iterr = np.argmin(mean_val_hist)\n",
    "    print('main iteration is:',main_iterr)\n",
    "    return main_iterr\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "69En-NF7ZXKj",
    "outputId": "48984026-8db1-4641-a035-a7ef64d7baf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 284 samples, validate on 72 samples\n",
      "Epoch 1/170\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 69.9470 - accuracy: 0.1831 - val_loss: 14.3449 - val_accuracy: 0.1806\n",
      "Epoch 2/170\n",
      "284/284 [==============================] - 0s 118us/step - loss: 74.2830 - accuracy: 0.2148 - val_loss: 7.1675 - val_accuracy: 0.2500\n",
      "Epoch 3/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 16.4546 - accuracy: 0.2254 - val_loss: 3.3666 - val_accuracy: 0.2917\n",
      "Epoch 4/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 64.0496 - accuracy: 0.2254 - val_loss: 2.2789 - val_accuracy: 0.2917\n",
      "Epoch 5/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 22.0619 - accuracy: 0.2218 - val_loss: 1.8791 - val_accuracy: 0.3194\n",
      "Epoch 6/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 13.2153 - accuracy: 0.2535 - val_loss: 1.7878 - val_accuracy: 0.3333\n",
      "Epoch 7/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 36.5306 - accuracy: 0.3028 - val_loss: 2.2648 - val_accuracy: 0.4306\n",
      "Epoch 8/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 52.6157 - accuracy: 0.2852 - val_loss: 7.9087 - val_accuracy: 0.3333\n",
      "Epoch 9/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 19.7194 - accuracy: 0.2641 - val_loss: 14.3750 - val_accuracy: 0.3889\n",
      "Epoch 10/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 7.7933 - accuracy: 0.2676 - val_loss: 9.0530 - val_accuracy: 0.4028\n",
      "Epoch 11/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 8.3024 - accuracy: 0.2782 - val_loss: 9.6931 - val_accuracy: 0.2222\n",
      "Epoch 12/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 4.7589 - accuracy: 0.3028 - val_loss: 8.1974 - val_accuracy: 0.3194\n",
      "Epoch 13/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 36.5763 - accuracy: 0.2394 - val_loss: 6.9699 - val_accuracy: 0.2639\n",
      "Epoch 14/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 6.4766 - accuracy: 0.2746 - val_loss: 4.5045 - val_accuracy: 0.3333\n",
      "Epoch 15/170\n",
      "284/284 [==============================] - 0s 120us/step - loss: 12.0956 - accuracy: 0.2711 - val_loss: 7.8819 - val_accuracy: 0.3472\n",
      "Epoch 16/170\n",
      "284/284 [==============================] - 0s 104us/step - loss: 4.0205 - accuracy: 0.3099 - val_loss: 7.4173 - val_accuracy: 0.4028\n",
      "Epoch 17/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 7.3363 - accuracy: 0.3063 - val_loss: 5.4097 - val_accuracy: 0.3750\n",
      "Epoch 18/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 16.4224 - accuracy: 0.3134 - val_loss: 1.9550 - val_accuracy: 0.4444\n",
      "Epoch 19/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 20.8675 - accuracy: 0.3838 - val_loss: 1.5450 - val_accuracy: 0.4861\n",
      "Epoch 20/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 3.0104 - accuracy: 0.3873 - val_loss: 7.2890 - val_accuracy: 0.3750\n",
      "Epoch 21/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 30.1166 - accuracy: 0.3169 - val_loss: 12.2905 - val_accuracy: 0.4167\n",
      "Epoch 22/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 6.2073 - accuracy: 0.3592 - val_loss: 15.0218 - val_accuracy: 0.4167\n",
      "Epoch 23/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 5.1673 - accuracy: 0.3627 - val_loss: 17.7205 - val_accuracy: 0.4028\n",
      "Epoch 24/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 8.3606 - accuracy: 0.4225 - val_loss: 17.0639 - val_accuracy: 0.4167\n",
      "Epoch 25/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 4.9394 - accuracy: 0.3521 - val_loss: 15.4019 - val_accuracy: 0.4167\n",
      "Epoch 26/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 5.0145 - accuracy: 0.4085 - val_loss: 13.1664 - val_accuracy: 0.4167\n",
      "Epoch 27/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 5.1136 - accuracy: 0.3838 - val_loss: 9.8163 - val_accuracy: 0.4306\n",
      "Epoch 28/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 3.9634 - accuracy: 0.3662 - val_loss: 8.3849 - val_accuracy: 0.3750\n",
      "Epoch 29/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 2.8271 - accuracy: 0.3979 - val_loss: 8.2343 - val_accuracy: 0.4167\n",
      "Epoch 30/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 5.4079 - accuracy: 0.3275 - val_loss: 8.4068 - val_accuracy: 0.3194\n",
      "Epoch 31/170\n",
      "284/284 [==============================] - 0s 117us/step - loss: 7.3274 - accuracy: 0.3486 - val_loss: 16.8714 - val_accuracy: 0.2778\n",
      "Epoch 32/170\n",
      "284/284 [==============================] - 0s 124us/step - loss: 9.5994 - accuracy: 0.3768 - val_loss: 17.5814 - val_accuracy: 0.3194\n",
      "Epoch 33/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 3.2389 - accuracy: 0.3768 - val_loss: 15.5163 - val_accuracy: 0.3333\n",
      "Epoch 34/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 5.7331 - accuracy: 0.3592 - val_loss: 12.0314 - val_accuracy: 0.3333\n",
      "Epoch 35/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 4.7764 - accuracy: 0.4014 - val_loss: 3.8975 - val_accuracy: 0.4306\n",
      "Epoch 36/170\n",
      "284/284 [==============================] - 0s 119us/step - loss: 4.8558 - accuracy: 0.3732 - val_loss: 3.0032 - val_accuracy: 0.4167\n",
      "Epoch 37/170\n",
      "284/284 [==============================] - 0s 118us/step - loss: 6.0610 - accuracy: 0.3908 - val_loss: 3.6290 - val_accuracy: 0.4028\n",
      "Epoch 38/170\n",
      "284/284 [==============================] - 0s 119us/step - loss: 4.5679 - accuracy: 0.3592 - val_loss: 6.9868 - val_accuracy: 0.4028\n",
      "Epoch 39/170\n",
      "284/284 [==============================] - 0s 116us/step - loss: 3.9291 - accuracy: 0.3838 - val_loss: 9.5543 - val_accuracy: 0.4167\n",
      "Epoch 40/170\n",
      "284/284 [==============================] - 0s 120us/step - loss: 3.0598 - accuracy: 0.3486 - val_loss: 8.1064 - val_accuracy: 0.4167\n",
      "Epoch 41/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 3.0041 - accuracy: 0.4014 - val_loss: 5.1991 - val_accuracy: 0.4167\n",
      "Epoch 42/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 8.2228 - accuracy: 0.3873 - val_loss: 7.1383 - val_accuracy: 0.4167\n",
      "Epoch 43/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 5.5162 - accuracy: 0.3592 - val_loss: 5.2482 - val_accuracy: 0.4167\n",
      "Epoch 44/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 5.8681 - accuracy: 0.4014 - val_loss: 5.8844 - val_accuracy: 0.3611\n",
      "Epoch 45/170\n",
      "284/284 [==============================] - 0s 157us/step - loss: 2.9792 - accuracy: 0.4049 - val_loss: 6.6896 - val_accuracy: 0.4028\n",
      "Epoch 46/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 3.8731 - accuracy: 0.3944 - val_loss: 5.1512 - val_accuracy: 0.4028\n",
      "Epoch 47/170\n",
      "284/284 [==============================] - 0s 106us/step - loss: 3.4053 - accuracy: 0.3944 - val_loss: 4.3717 - val_accuracy: 0.4167\n",
      "Epoch 48/170\n",
      "284/284 [==============================] - 0s 120us/step - loss: 2.4598 - accuracy: 0.3908 - val_loss: 3.4340 - val_accuracy: 0.4167\n",
      "Epoch 49/170\n",
      "284/284 [==============================] - 0s 136us/step - loss: 2.5640 - accuracy: 0.4120 - val_loss: 2.9051 - val_accuracy: 0.4167\n",
      "Epoch 50/170\n",
      "284/284 [==============================] - 0s 120us/step - loss: 5.3461 - accuracy: 0.4014 - val_loss: 2.0770 - val_accuracy: 0.4028\n",
      "Epoch 51/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.6931 - accuracy: 0.3838 - val_loss: 2.3403 - val_accuracy: 0.4167\n",
      "Epoch 52/170\n",
      "284/284 [==============================] - 0s 135us/step - loss: 2.5884 - accuracy: 0.4120 - val_loss: 4.8436 - val_accuracy: 0.4028\n",
      "Epoch 53/170\n",
      "284/284 [==============================] - 0s 116us/step - loss: 2.0948 - accuracy: 0.3838 - val_loss: 4.8838 - val_accuracy: 0.4306\n",
      "Epoch 54/170\n",
      "284/284 [==============================] - 0s 122us/step - loss: 2.5021 - accuracy: 0.3873 - val_loss: 4.5653 - val_accuracy: 0.4167\n",
      "Epoch 55/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 2.8690 - accuracy: 0.4049 - val_loss: 3.6907 - val_accuracy: 0.4583\n",
      "Epoch 56/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 2.1009 - accuracy: 0.3873 - val_loss: 3.3745 - val_accuracy: 0.4583\n",
      "Epoch 57/170\n",
      "284/284 [==============================] - 0s 118us/step - loss: 2.2239 - accuracy: 0.3803 - val_loss: 2.8061 - val_accuracy: 0.4444\n",
      "Epoch 58/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 1.8425 - accuracy: 0.3873 - val_loss: 2.4084 - val_accuracy: 0.4583\n",
      "Epoch 59/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.8625 - accuracy: 0.4014 - val_loss: 1.8609 - val_accuracy: 0.4444\n",
      "Epoch 60/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5453 - accuracy: 0.4331 - val_loss: 1.5116 - val_accuracy: 0.4306\n",
      "Epoch 61/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.7588 - accuracy: 0.4049 - val_loss: 1.5030 - val_accuracy: 0.4444\n",
      "Epoch 62/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.6937 - accuracy: 0.3944 - val_loss: 1.5382 - val_accuracy: 0.4444\n",
      "Epoch 63/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.6192 - accuracy: 0.4014 - val_loss: 1.5092 - val_accuracy: 0.4444\n",
      "Epoch 64/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.5680 - accuracy: 0.3979 - val_loss: 1.4988 - val_accuracy: 0.4444\n",
      "Epoch 65/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 6.7658 - accuracy: 0.3627 - val_loss: 1.5151 - val_accuracy: 0.4722\n",
      "Epoch 66/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.7724 - accuracy: 0.3803 - val_loss: 1.4856 - val_accuracy: 0.4583\n",
      "Epoch 67/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.5667 - accuracy: 0.3979 - val_loss: 1.4600 - val_accuracy: 0.4444\n",
      "Epoch 68/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 2.7330 - accuracy: 0.3627 - val_loss: 2.4050 - val_accuracy: 0.4306\n",
      "Epoch 69/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 2.8499 - accuracy: 0.3908 - val_loss: 3.7725 - val_accuracy: 0.4444\n",
      "Epoch 70/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 2.7201 - accuracy: 0.4190 - val_loss: 4.3605 - val_accuracy: 0.4444\n",
      "Epoch 71/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 2.2574 - accuracy: 0.4120 - val_loss: 3.5870 - val_accuracy: 0.4861\n",
      "Epoch 72/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 2.4699 - accuracy: 0.4014 - val_loss: 2.9102 - val_accuracy: 0.4861\n",
      "Epoch 73/170\n",
      "284/284 [==============================] - 0s 116us/step - loss: 1.8560 - accuracy: 0.4120 - val_loss: 2.4213 - val_accuracy: 0.4722\n",
      "Epoch 74/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.9412 - accuracy: 0.3979 - val_loss: 1.9923 - val_accuracy: 0.4722\n",
      "Epoch 75/170\n",
      "284/284 [==============================] - 0s 116us/step - loss: 1.6525 - accuracy: 0.4261 - val_loss: 1.6391 - val_accuracy: 0.4861\n",
      "Epoch 76/170\n",
      "284/284 [==============================] - 0s 119us/step - loss: 1.5793 - accuracy: 0.4225 - val_loss: 1.4518 - val_accuracy: 0.4722\n",
      "Epoch 77/170\n",
      "284/284 [==============================] - 0s 117us/step - loss: 3.5536 - accuracy: 0.4120 - val_loss: 2.1820 - val_accuracy: 0.5000\n",
      "Epoch 78/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 2.0411 - accuracy: 0.4014 - val_loss: 2.3074 - val_accuracy: 0.5000\n",
      "Epoch 79/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.8805 - accuracy: 0.4190 - val_loss: 1.4250 - val_accuracy: 0.4861\n",
      "Epoch 80/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 2.3944 - accuracy: 0.4014 - val_loss: 2.9542 - val_accuracy: 0.4861\n",
      "Epoch 81/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.8601 - accuracy: 0.4014 - val_loss: 3.6509 - val_accuracy: 0.4444\n",
      "Epoch 82/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 2.1784 - accuracy: 0.4049 - val_loss: 3.5060 - val_accuracy: 0.4861\n",
      "Epoch 83/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 1.7180 - accuracy: 0.4155 - val_loss: 3.2375 - val_accuracy: 0.4722\n",
      "Epoch 84/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 2.0763 - accuracy: 0.3838 - val_loss: 2.9373 - val_accuracy: 0.5000\n",
      "Epoch 85/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 2.5702 - accuracy: 0.3944 - val_loss: 2.5215 - val_accuracy: 0.4722\n",
      "Epoch 86/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 2.2210 - accuracy: 0.4437 - val_loss: 1.7116 - val_accuracy: 0.4444\n",
      "Epoch 87/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.5927 - accuracy: 0.4014 - val_loss: 1.4757 - val_accuracy: 0.4722\n",
      "Epoch 88/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.7026 - accuracy: 0.3697 - val_loss: 1.4770 - val_accuracy: 0.4583\n",
      "Epoch 89/170\n",
      "284/284 [==============================] - 0s 118us/step - loss: 1.5638 - accuracy: 0.4014 - val_loss: 1.4442 - val_accuracy: 0.4583\n",
      "Epoch 90/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.5283 - accuracy: 0.4049 - val_loss: 1.4467 - val_accuracy: 0.4444\n",
      "Epoch 91/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.5761 - accuracy: 0.3838 - val_loss: 1.4858 - val_accuracy: 0.4583\n",
      "Epoch 92/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.5664 - accuracy: 0.3803 - val_loss: 1.4435 - val_accuracy: 0.4722\n",
      "Epoch 93/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.5032 - accuracy: 0.4120 - val_loss: 1.4200 - val_accuracy: 0.4583\n",
      "Epoch 94/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.5227 - accuracy: 0.4049 - val_loss: 1.4203 - val_accuracy: 0.4583\n",
      "Epoch 95/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5132 - accuracy: 0.3944 - val_loss: 1.4322 - val_accuracy: 0.4722\n",
      "Epoch 96/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.5332 - accuracy: 0.3979 - val_loss: 1.4309 - val_accuracy: 0.4722\n",
      "Epoch 97/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.5234 - accuracy: 0.4014 - val_loss: 1.4411 - val_accuracy: 0.4583\n",
      "Epoch 98/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.5137 - accuracy: 0.4049 - val_loss: 1.4065 - val_accuracy: 0.4444\n",
      "Epoch 99/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 1.5178 - accuracy: 0.3979 - val_loss: 1.4624 - val_accuracy: 0.4722\n",
      "Epoch 100/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5436 - accuracy: 0.3873 - val_loss: 1.4175 - val_accuracy: 0.4444\n",
      "Epoch 101/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.5288 - accuracy: 0.4085 - val_loss: 1.4436 - val_accuracy: 0.4722\n",
      "Epoch 102/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 1.5208 - accuracy: 0.3908 - val_loss: 1.4079 - val_accuracy: 0.4861\n",
      "Epoch 103/170\n",
      "284/284 [==============================] - 0s 127us/step - loss: 1.5125 - accuracy: 0.4049 - val_loss: 1.4407 - val_accuracy: 0.4722\n",
      "Epoch 104/170\n",
      "284/284 [==============================] - 0s 120us/step - loss: 1.5153 - accuracy: 0.3908 - val_loss: 1.3934 - val_accuracy: 0.4861\n",
      "Epoch 105/170\n",
      "284/284 [==============================] - 0s 118us/step - loss: 1.5182 - accuracy: 0.4049 - val_loss: 1.4535 - val_accuracy: 0.4722\n",
      "Epoch 106/170\n",
      "284/284 [==============================] - 0s 134us/step - loss: 1.5292 - accuracy: 0.3979 - val_loss: 1.4105 - val_accuracy: 0.4861\n",
      "Epoch 107/170\n",
      "284/284 [==============================] - 0s 120us/step - loss: 1.5153 - accuracy: 0.4049 - val_loss: 1.4081 - val_accuracy: 0.4722\n",
      "Epoch 108/170\n",
      "284/284 [==============================] - 0s 106us/step - loss: 1.4920 - accuracy: 0.4261 - val_loss: 1.3919 - val_accuracy: 0.4722\n",
      "Epoch 109/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.5132 - accuracy: 0.3944 - val_loss: 1.4021 - val_accuracy: 0.4861\n",
      "Epoch 110/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.5345 - accuracy: 0.3944 - val_loss: 1.4918 - val_accuracy: 0.4444\n",
      "Epoch 111/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.5575 - accuracy: 0.3768 - val_loss: 1.4009 - val_accuracy: 0.4583\n",
      "Epoch 112/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.5122 - accuracy: 0.4155 - val_loss: 1.4096 - val_accuracy: 0.4583\n",
      "Epoch 113/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 1.4952 - accuracy: 0.4331 - val_loss: 1.3803 - val_accuracy: 0.4861\n",
      "Epoch 114/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.5494 - accuracy: 0.4085 - val_loss: 1.4397 - val_accuracy: 0.4722\n",
      "Epoch 115/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.5027 - accuracy: 0.3908 - val_loss: 1.3929 - val_accuracy: 0.4722\n",
      "Epoch 116/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.5065 - accuracy: 0.4296 - val_loss: 1.3915 - val_accuracy: 0.4861\n",
      "Epoch 117/170\n",
      "284/284 [==============================] - 0s 111us/step - loss: 1.5022 - accuracy: 0.3979 - val_loss: 1.3733 - val_accuracy: 0.4861\n",
      "Epoch 118/170\n",
      "284/284 [==============================] - 0s 116us/step - loss: 1.5228 - accuracy: 0.4155 - val_loss: 1.3926 - val_accuracy: 0.4583\n",
      "Epoch 119/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5183 - accuracy: 0.3979 - val_loss: 1.4102 - val_accuracy: 0.4722\n",
      "Epoch 120/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.4958 - accuracy: 0.4085 - val_loss: 1.3825 - val_accuracy: 0.4583\n",
      "Epoch 121/170\n",
      "284/284 [==============================] - 0s 106us/step - loss: 1.5046 - accuracy: 0.4085 - val_loss: 1.3659 - val_accuracy: 0.5000\n",
      "Epoch 122/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.5019 - accuracy: 0.4225 - val_loss: 1.4263 - val_accuracy: 0.4722\n",
      "Epoch 123/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 1.5332 - accuracy: 0.4014 - val_loss: 1.3862 - val_accuracy: 0.4444\n",
      "Epoch 124/170\n",
      "284/284 [==============================] - 0s 103us/step - loss: 1.5033 - accuracy: 0.4049 - val_loss: 1.4208 - val_accuracy: 0.4722\n",
      "Epoch 125/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.4985 - accuracy: 0.4120 - val_loss: 1.3679 - val_accuracy: 0.5000\n",
      "Epoch 126/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 1.4660 - accuracy: 0.4049 - val_loss: 1.3883 - val_accuracy: 0.4722\n",
      "Epoch 127/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 1.4741 - accuracy: 0.4331 - val_loss: 1.3559 - val_accuracy: 0.5000\n",
      "Epoch 128/170\n",
      "284/284 [==============================] - 0s 106us/step - loss: 1.5138 - accuracy: 0.4049 - val_loss: 1.3882 - val_accuracy: 0.4722\n",
      "Epoch 129/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 1.5190 - accuracy: 0.3979 - val_loss: 1.4006 - val_accuracy: 0.4861\n",
      "Epoch 130/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.4755 - accuracy: 0.4190 - val_loss: 1.4021 - val_accuracy: 0.4722\n",
      "Epoch 131/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5034 - accuracy: 0.4155 - val_loss: 1.3812 - val_accuracy: 0.4861\n",
      "Epoch 132/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 1.4679 - accuracy: 0.4085 - val_loss: 1.3577 - val_accuracy: 0.5000\n",
      "Epoch 133/170\n",
      "284/284 [==============================] - 0s 116us/step - loss: 1.4991 - accuracy: 0.4120 - val_loss: 1.3799 - val_accuracy: 0.4722\n",
      "Epoch 134/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 1.5018 - accuracy: 0.4049 - val_loss: 1.3547 - val_accuracy: 0.5000\n",
      "Epoch 135/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.4872 - accuracy: 0.4190 - val_loss: 1.3852 - val_accuracy: 0.5000\n",
      "Epoch 136/170\n",
      "284/284 [==============================] - 0s 104us/step - loss: 1.4773 - accuracy: 0.4049 - val_loss: 1.3724 - val_accuracy: 0.4861\n",
      "Epoch 137/170\n",
      "284/284 [==============================] - 0s 106us/step - loss: 1.5142 - accuracy: 0.3944 - val_loss: 1.4297 - val_accuracy: 0.4444\n",
      "Epoch 138/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.4734 - accuracy: 0.4225 - val_loss: 1.3718 - val_accuracy: 0.4722\n",
      "Epoch 139/170\n",
      "284/284 [==============================] - 0s 112us/step - loss: 1.4869 - accuracy: 0.4085 - val_loss: 1.4050 - val_accuracy: 0.4722\n",
      "Epoch 140/170\n",
      "284/284 [==============================] - 0s 104us/step - loss: 1.4556 - accuracy: 0.4366 - val_loss: 1.3652 - val_accuracy: 0.4444\n",
      "Epoch 141/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5142 - accuracy: 0.4014 - val_loss: 1.4164 - val_accuracy: 0.4583\n",
      "Epoch 142/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.4673 - accuracy: 0.4190 - val_loss: 1.3553 - val_accuracy: 0.5000\n",
      "Epoch 143/170\n",
      "284/284 [==============================] - 0s 103us/step - loss: 1.4881 - accuracy: 0.4049 - val_loss: 1.3731 - val_accuracy: 0.4861\n",
      "Epoch 144/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.5041 - accuracy: 0.3979 - val_loss: 1.3586 - val_accuracy: 0.5139\n",
      "Epoch 145/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 1.4909 - accuracy: 0.4085 - val_loss: 1.3575 - val_accuracy: 0.4583\n",
      "Epoch 146/170\n",
      "284/284 [==============================] - 0s 102us/step - loss: 1.4741 - accuracy: 0.4401 - val_loss: 1.3808 - val_accuracy: 0.4861\n",
      "Epoch 147/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 1.4484 - accuracy: 0.4120 - val_loss: 1.3384 - val_accuracy: 0.5000\n",
      "Epoch 148/170\n",
      "284/284 [==============================] - 0s 102us/step - loss: 1.5073 - accuracy: 0.4014 - val_loss: 1.3438 - val_accuracy: 0.5000\n",
      "Epoch 149/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.4804 - accuracy: 0.4331 - val_loss: 1.3627 - val_accuracy: 0.5000\n",
      "Epoch 150/170\n",
      "284/284 [==============================] - 0s 115us/step - loss: 1.5135 - accuracy: 0.4014 - val_loss: 1.3503 - val_accuracy: 0.5139\n",
      "Epoch 151/170\n",
      "284/284 [==============================] - 0s 107us/step - loss: 1.4671 - accuracy: 0.4296 - val_loss: 1.3477 - val_accuracy: 0.4861\n",
      "Epoch 152/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.4916 - accuracy: 0.4225 - val_loss: 1.3745 - val_accuracy: 0.5000\n",
      "Epoch 153/170\n",
      "284/284 [==============================] - 0s 104us/step - loss: 1.4676 - accuracy: 0.4190 - val_loss: 1.3426 - val_accuracy: 0.5000\n",
      "Epoch 154/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.4558 - accuracy: 0.4190 - val_loss: 1.3619 - val_accuracy: 0.5000\n",
      "Epoch 155/170\n",
      "284/284 [==============================] - 0s 101us/step - loss: 1.4376 - accuracy: 0.4261 - val_loss: 1.3281 - val_accuracy: 0.5000\n",
      "Epoch 156/170\n",
      "284/284 [==============================] - 0s 106us/step - loss: 1.4767 - accuracy: 0.4085 - val_loss: 1.3456 - val_accuracy: 0.5000\n",
      "Epoch 157/170\n",
      "284/284 [==============================] - 0s 104us/step - loss: 1.4751 - accuracy: 0.4225 - val_loss: 1.3434 - val_accuracy: 0.5000\n",
      "Epoch 158/170\n",
      "284/284 [==============================] - 0s 109us/step - loss: 1.4561 - accuracy: 0.4190 - val_loss: 1.3526 - val_accuracy: 0.5000\n",
      "Epoch 159/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.4419 - accuracy: 0.4331 - val_loss: 1.3219 - val_accuracy: 0.5000\n",
      "Epoch 160/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 1.4950 - accuracy: 0.4155 - val_loss: 1.3977 - val_accuracy: 0.4583\n",
      "Epoch 161/170\n",
      "284/284 [==============================] - 0s 105us/step - loss: 1.5223 - accuracy: 0.4085 - val_loss: 1.3427 - val_accuracy: 0.5000\n",
      "Epoch 162/170\n",
      "284/284 [==============================] - 0s 108us/step - loss: 1.4442 - accuracy: 0.4401 - val_loss: 1.3483 - val_accuracy: 0.5000\n",
      "Epoch 163/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.4758 - accuracy: 0.4120 - val_loss: 1.3555 - val_accuracy: 0.5000\n",
      "Epoch 164/170\n",
      "284/284 [==============================] - 0s 134us/step - loss: 1.4791 - accuracy: 0.4014 - val_loss: 1.3448 - val_accuracy: 0.5000\n",
      "Epoch 165/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.4530 - accuracy: 0.4155 - val_loss: 1.3386 - val_accuracy: 0.5000\n",
      "Epoch 166/170\n",
      "284/284 [==============================] - 0s 110us/step - loss: 1.4738 - accuracy: 0.4225 - val_loss: 1.3468 - val_accuracy: 0.5139\n",
      "Epoch 167/170\n",
      "284/284 [==============================] - 0s 114us/step - loss: 1.4834 - accuracy: 0.4049 - val_loss: 1.3449 - val_accuracy: 0.5139\n",
      "Epoch 168/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 1.4669 - accuracy: 0.4190 - val_loss: 1.3346 - val_accuracy: 0.5000\n",
      "Epoch 169/170\n",
      "284/284 [==============================] - 0s 113us/step - loss: 1.4810 - accuracy: 0.4155 - val_loss: 1.3681 - val_accuracy: 0.5000\n",
      "Epoch 170/170\n",
      "284/284 [==============================] - 0s 103us/step - loss: 1.4563 - accuracy: 0.4261 - val_loss: 1.3316 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 285 samples, validate on 71 samples\n",
      "Epoch 1/170\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 36.4761 - accuracy: 0.3088 - val_loss: 45.5384 - val_accuracy: 0.2254\n",
      "Epoch 2/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 22.0102 - accuracy: 0.3263 - val_loss: 32.8339 - val_accuracy: 0.2254\n",
      "Epoch 3/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 25.0369 - accuracy: 0.3228 - val_loss: 24.1295 - val_accuracy: 0.2817\n",
      "Epoch 4/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 27.6364 - accuracy: 0.3193 - val_loss: 17.0841 - val_accuracy: 0.2958\n",
      "Epoch 5/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 16.1003 - accuracy: 0.3544 - val_loss: 13.2329 - val_accuracy: 0.2958\n",
      "Epoch 6/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 13.5480 - accuracy: 0.3509 - val_loss: 8.9272 - val_accuracy: 0.2958\n",
      "Epoch 7/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 10.5034 - accuracy: 0.3018 - val_loss: 5.6152 - val_accuracy: 0.3239\n",
      "Epoch 8/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 5.1540 - accuracy: 0.3193 - val_loss: 4.2816 - val_accuracy: 0.2958\n",
      "Epoch 9/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 8.3996 - accuracy: 0.2912 - val_loss: 4.1529 - val_accuracy: 0.2394\n",
      "Epoch 10/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 4.4044 - accuracy: 0.2632 - val_loss: 3.9220 - val_accuracy: 0.1972\n",
      "Epoch 11/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 4.4984 - accuracy: 0.3193 - val_loss: 3.5806 - val_accuracy: 0.2394\n",
      "Epoch 12/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 3.7985 - accuracy: 0.3439 - val_loss: 2.7447 - val_accuracy: 0.2394\n",
      "Epoch 13/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 3.4897 - accuracy: 0.2982 - val_loss: 1.9421 - val_accuracy: 0.2394\n",
      "Epoch 14/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 2.2720 - accuracy: 0.2842 - val_loss: 2.3250 - val_accuracy: 0.1972\n",
      "Epoch 15/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 2.9384 - accuracy: 0.3333 - val_loss: 1.9229 - val_accuracy: 0.2535\n",
      "Epoch 16/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 3.1892 - accuracy: 0.3263 - val_loss: 2.4898 - val_accuracy: 0.2817\n",
      "Epoch 17/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 3.1553 - accuracy: 0.3228 - val_loss: 2.3769 - val_accuracy: 0.2535\n",
      "Epoch 18/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 2.2132 - accuracy: 0.3298 - val_loss: 1.7103 - val_accuracy: 0.3099\n",
      "Epoch 19/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.9886 - accuracy: 0.3509 - val_loss: 1.8500 - val_accuracy: 0.2958\n",
      "Epoch 20/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.7078 - accuracy: 0.3404 - val_loss: 1.7700 - val_accuracy: 0.3521\n",
      "Epoch 21/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.7093 - accuracy: 0.3930 - val_loss: 1.7596 - val_accuracy: 0.3521\n",
      "Epoch 22/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6665 - accuracy: 0.3825 - val_loss: 1.7605 - val_accuracy: 0.3521\n",
      "Epoch 23/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6516 - accuracy: 0.3930 - val_loss: 1.7589 - val_accuracy: 0.3803\n",
      "Epoch 24/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.6726 - accuracy: 0.4070 - val_loss: 1.7590 - val_accuracy: 0.3662\n",
      "Epoch 25/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6557 - accuracy: 0.4105 - val_loss: 1.7525 - val_accuracy: 0.3944\n",
      "Epoch 26/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6716 - accuracy: 0.4281 - val_loss: 1.7539 - val_accuracy: 0.4085\n",
      "Epoch 27/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6564 - accuracy: 0.4000 - val_loss: 1.7371 - val_accuracy: 0.3662\n",
      "Epoch 28/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6543 - accuracy: 0.4000 - val_loss: 1.7510 - val_accuracy: 0.3944\n",
      "Epoch 29/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6411 - accuracy: 0.4140 - val_loss: 1.7431 - val_accuracy: 0.3944\n",
      "Epoch 30/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.6243 - accuracy: 0.3930 - val_loss: 1.7490 - val_accuracy: 0.4085\n",
      "Epoch 31/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6300 - accuracy: 0.4070 - val_loss: 1.7335 - val_accuracy: 0.3944\n",
      "Epoch 32/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.6389 - accuracy: 0.4070 - val_loss: 1.7300 - val_accuracy: 0.3944\n",
      "Epoch 33/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6558 - accuracy: 0.3930 - val_loss: 1.7428 - val_accuracy: 0.4085\n",
      "Epoch 34/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6433 - accuracy: 0.3754 - val_loss: 1.7231 - val_accuracy: 0.4085\n",
      "Epoch 35/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6030 - accuracy: 0.4070 - val_loss: 1.7244 - val_accuracy: 0.4085\n",
      "Epoch 36/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6051 - accuracy: 0.4246 - val_loss: 1.7395 - val_accuracy: 0.3662\n",
      "Epoch 37/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.6452 - accuracy: 0.4035 - val_loss: 1.7162 - val_accuracy: 0.3944\n",
      "Epoch 38/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6072 - accuracy: 0.4140 - val_loss: 1.7135 - val_accuracy: 0.3944\n",
      "Epoch 39/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6281 - accuracy: 0.4105 - val_loss: 1.7135 - val_accuracy: 0.4085\n",
      "Epoch 40/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5734 - accuracy: 0.4211 - val_loss: 1.7127 - val_accuracy: 0.4366\n",
      "Epoch 41/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.6113 - accuracy: 0.3930 - val_loss: 1.7068 - val_accuracy: 0.4085\n",
      "Epoch 42/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6152 - accuracy: 0.3754 - val_loss: 1.7045 - val_accuracy: 0.4085\n",
      "Epoch 43/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5924 - accuracy: 0.3860 - val_loss: 1.7080 - val_accuracy: 0.4085\n",
      "Epoch 44/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5776 - accuracy: 0.4175 - val_loss: 1.7138 - val_accuracy: 0.4225\n",
      "Epoch 45/170\n",
      "285/285 [==============================] - 0s 124us/step - loss: 1.5999 - accuracy: 0.4000 - val_loss: 1.7067 - val_accuracy: 0.3662\n",
      "Epoch 46/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6136 - accuracy: 0.4000 - val_loss: 1.6934 - val_accuracy: 0.4366\n",
      "Epoch 47/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5912 - accuracy: 0.3789 - val_loss: 1.7058 - val_accuracy: 0.4085\n",
      "Epoch 48/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.5842 - accuracy: 0.4035 - val_loss: 1.6978 - val_accuracy: 0.4648\n",
      "Epoch 49/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5691 - accuracy: 0.4246 - val_loss: 1.6918 - val_accuracy: 0.4225\n",
      "Epoch 50/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5855 - accuracy: 0.3789 - val_loss: 1.6994 - val_accuracy: 0.4366\n",
      "Epoch 51/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5807 - accuracy: 0.3930 - val_loss: 1.6806 - val_accuracy: 0.4648\n",
      "Epoch 52/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5579 - accuracy: 0.4211 - val_loss: 1.6839 - val_accuracy: 0.4366\n",
      "Epoch 53/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5831 - accuracy: 0.4140 - val_loss: 1.6765 - val_accuracy: 0.4507\n",
      "Epoch 54/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5678 - accuracy: 0.4105 - val_loss: 1.7053 - val_accuracy: 0.4366\n",
      "Epoch 55/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5802 - accuracy: 0.4316 - val_loss: 1.6672 - val_accuracy: 0.4648\n",
      "Epoch 56/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5651 - accuracy: 0.4175 - val_loss: 1.6800 - val_accuracy: 0.4085\n",
      "Epoch 57/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5357 - accuracy: 0.4175 - val_loss: 1.6771 - val_accuracy: 0.4507\n",
      "Epoch 58/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5824 - accuracy: 0.4035 - val_loss: 1.6676 - val_accuracy: 0.4507\n",
      "Epoch 59/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5679 - accuracy: 0.4035 - val_loss: 1.6687 - val_accuracy: 0.4648\n",
      "Epoch 60/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5369 - accuracy: 0.4105 - val_loss: 1.6673 - val_accuracy: 0.4366\n",
      "Epoch 61/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5349 - accuracy: 0.4105 - val_loss: 1.6632 - val_accuracy: 0.4366\n",
      "Epoch 62/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5578 - accuracy: 0.4175 - val_loss: 1.6566 - val_accuracy: 0.4648\n",
      "Epoch 63/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5586 - accuracy: 0.4281 - val_loss: 1.6503 - val_accuracy: 0.4648\n",
      "Epoch 64/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5249 - accuracy: 0.4281 - val_loss: 1.6528 - val_accuracy: 0.4789\n",
      "Epoch 65/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5608 - accuracy: 0.4000 - val_loss: 1.6383 - val_accuracy: 0.4648\n",
      "Epoch 66/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5384 - accuracy: 0.4246 - val_loss: 1.6662 - val_accuracy: 0.4648\n",
      "Epoch 67/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5224 - accuracy: 0.4421 - val_loss: 1.6518 - val_accuracy: 0.4507\n",
      "Epoch 68/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5238 - accuracy: 0.4246 - val_loss: 1.6345 - val_accuracy: 0.4930\n",
      "Epoch 69/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5271 - accuracy: 0.4140 - val_loss: 1.6462 - val_accuracy: 0.4507\n",
      "Epoch 70/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5715 - accuracy: 0.4000 - val_loss: 1.6424 - val_accuracy: 0.4930\n",
      "Epoch 71/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5338 - accuracy: 0.4421 - val_loss: 1.6367 - val_accuracy: 0.4789\n",
      "Epoch 72/170\n",
      "285/285 [==============================] - 0s 124us/step - loss: 1.5401 - accuracy: 0.4246 - val_loss: 1.6314 - val_accuracy: 0.4930\n",
      "Epoch 73/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.4888 - accuracy: 0.4526 - val_loss: 1.6538 - val_accuracy: 0.4507\n",
      "Epoch 74/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5292 - accuracy: 0.4140 - val_loss: 1.6265 - val_accuracy: 0.4789\n",
      "Epoch 75/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4868 - accuracy: 0.4632 - val_loss: 1.6311 - val_accuracy: 0.4648\n",
      "Epoch 76/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5304 - accuracy: 0.4211 - val_loss: 1.6177 - val_accuracy: 0.5070\n",
      "Epoch 77/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5024 - accuracy: 0.4702 - val_loss: 1.6358 - val_accuracy: 0.4789\n",
      "Epoch 78/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4891 - accuracy: 0.4386 - val_loss: 1.6104 - val_accuracy: 0.4930\n",
      "Epoch 79/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5173 - accuracy: 0.4386 - val_loss: 1.6175 - val_accuracy: 0.4930\n",
      "Epoch 80/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.4838 - accuracy: 0.4491 - val_loss: 1.6304 - val_accuracy: 0.4507\n",
      "Epoch 81/170\n",
      "285/285 [==============================] - 0s 147us/step - loss: 1.5272 - accuracy: 0.4105 - val_loss: 1.6117 - val_accuracy: 0.4930\n",
      "Epoch 82/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5202 - accuracy: 0.4316 - val_loss: 1.6302 - val_accuracy: 0.4507\n",
      "Epoch 83/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5228 - accuracy: 0.4421 - val_loss: 1.6140 - val_accuracy: 0.4648\n",
      "Epoch 84/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4775 - accuracy: 0.4596 - val_loss: 1.6108 - val_accuracy: 0.4648\n",
      "Epoch 85/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4583 - accuracy: 0.4737 - val_loss: 1.6313 - val_accuracy: 0.4507\n",
      "Epoch 86/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4525 - accuracy: 0.4842 - val_loss: 1.5898 - val_accuracy: 0.5352\n",
      "Epoch 87/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.4940 - accuracy: 0.4491 - val_loss: 1.6151 - val_accuracy: 0.4507\n",
      "Epoch 88/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4973 - accuracy: 0.4386 - val_loss: 1.5997 - val_accuracy: 0.5070\n",
      "Epoch 89/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4680 - accuracy: 0.4702 - val_loss: 1.5907 - val_accuracy: 0.4789\n",
      "Epoch 90/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.5047 - accuracy: 0.4526 - val_loss: 1.6478 - val_accuracy: 0.4930\n",
      "Epoch 91/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5067 - accuracy: 0.4281 - val_loss: 1.5977 - val_accuracy: 0.5070\n",
      "Epoch 92/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4965 - accuracy: 0.4211 - val_loss: 1.5776 - val_accuracy: 0.5211\n",
      "Epoch 93/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4755 - accuracy: 0.4491 - val_loss: 1.6017 - val_accuracy: 0.4648\n",
      "Epoch 94/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.5055 - accuracy: 0.4175 - val_loss: 1.5962 - val_accuracy: 0.5211\n",
      "Epoch 95/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5034 - accuracy: 0.4526 - val_loss: 1.5947 - val_accuracy: 0.5070\n",
      "Epoch 96/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4530 - accuracy: 0.4316 - val_loss: 1.5877 - val_accuracy: 0.5070\n",
      "Epoch 97/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4665 - accuracy: 0.4491 - val_loss: 1.5894 - val_accuracy: 0.5070\n",
      "Epoch 98/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4764 - accuracy: 0.4596 - val_loss: 1.5964 - val_accuracy: 0.5211\n",
      "Epoch 99/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4381 - accuracy: 0.4877 - val_loss: 1.5802 - val_accuracy: 0.5211\n",
      "Epoch 100/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4458 - accuracy: 0.4807 - val_loss: 1.5899 - val_accuracy: 0.5211\n",
      "Epoch 101/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4783 - accuracy: 0.4456 - val_loss: 1.5910 - val_accuracy: 0.5070\n",
      "Epoch 102/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4782 - accuracy: 0.4596 - val_loss: 1.5700 - val_accuracy: 0.5070\n",
      "Epoch 103/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4568 - accuracy: 0.4351 - val_loss: 1.5863 - val_accuracy: 0.5070\n",
      "Epoch 104/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4698 - accuracy: 0.4386 - val_loss: 1.5761 - val_accuracy: 0.5211\n",
      "Epoch 105/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4788 - accuracy: 0.4246 - val_loss: 1.5780 - val_accuracy: 0.5211\n",
      "Epoch 106/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4747 - accuracy: 0.4456 - val_loss: 1.5737 - val_accuracy: 0.5211\n",
      "Epoch 107/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4699 - accuracy: 0.4491 - val_loss: 1.5684 - val_accuracy: 0.5070\n",
      "Epoch 108/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4205 - accuracy: 0.4632 - val_loss: 1.5897 - val_accuracy: 0.4930\n",
      "Epoch 109/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4464 - accuracy: 0.4456 - val_loss: 1.5779 - val_accuracy: 0.5211\n",
      "Epoch 110/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4283 - accuracy: 0.4702 - val_loss: 1.5578 - val_accuracy: 0.5352\n",
      "Epoch 111/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 1.4273 - accuracy: 0.4632 - val_loss: 1.5622 - val_accuracy: 0.4930\n",
      "Epoch 112/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5133 - accuracy: 0.4035 - val_loss: 1.5645 - val_accuracy: 0.5211\n",
      "Epoch 113/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4599 - accuracy: 0.4632 - val_loss: 1.5846 - val_accuracy: 0.4648\n",
      "Epoch 114/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.3935 - accuracy: 0.4807 - val_loss: 1.5570 - val_accuracy: 0.5352\n",
      "Epoch 115/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4584 - accuracy: 0.4632 - val_loss: 1.5610 - val_accuracy: 0.5211\n",
      "Epoch 116/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4718 - accuracy: 0.4281 - val_loss: 1.5750 - val_accuracy: 0.5352\n",
      "Epoch 117/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4711 - accuracy: 0.4526 - val_loss: 1.5477 - val_accuracy: 0.5211\n",
      "Epoch 118/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.4627 - accuracy: 0.4596 - val_loss: 1.5908 - val_accuracy: 0.4930\n",
      "Epoch 119/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4484 - accuracy: 0.4702 - val_loss: 1.5634 - val_accuracy: 0.4789\n",
      "Epoch 120/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4551 - accuracy: 0.4667 - val_loss: 1.5499 - val_accuracy: 0.4930\n",
      "Epoch 121/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4765 - accuracy: 0.4386 - val_loss: 1.5604 - val_accuracy: 0.5352\n",
      "Epoch 122/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4494 - accuracy: 0.4456 - val_loss: 1.5682 - val_accuracy: 0.5070\n",
      "Epoch 123/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4355 - accuracy: 0.4386 - val_loss: 1.5510 - val_accuracy: 0.5211\n",
      "Epoch 124/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4419 - accuracy: 0.4456 - val_loss: 1.5687 - val_accuracy: 0.5070\n",
      "Epoch 125/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4511 - accuracy: 0.4596 - val_loss: 1.5338 - val_accuracy: 0.5070\n",
      "Epoch 126/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 1.4495 - accuracy: 0.4561 - val_loss: 1.5468 - val_accuracy: 0.5352\n",
      "Epoch 127/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4014 - accuracy: 0.4772 - val_loss: 1.5406 - val_accuracy: 0.5493\n",
      "Epoch 128/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4121 - accuracy: 0.4807 - val_loss: 1.5378 - val_accuracy: 0.5352\n",
      "Epoch 129/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4686 - accuracy: 0.4737 - val_loss: 1.5549 - val_accuracy: 0.5352\n",
      "Epoch 130/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4437 - accuracy: 0.4491 - val_loss: 1.5373 - val_accuracy: 0.5070\n",
      "Epoch 131/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4172 - accuracy: 0.4702 - val_loss: 1.5381 - val_accuracy: 0.5211\n",
      "Epoch 132/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4221 - accuracy: 0.4877 - val_loss: 1.5377 - val_accuracy: 0.5211\n",
      "Epoch 133/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 1.4229 - accuracy: 0.4772 - val_loss: 1.5473 - val_accuracy: 0.5211\n",
      "Epoch 134/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4274 - accuracy: 0.4772 - val_loss: 1.5223 - val_accuracy: 0.5070\n",
      "Epoch 135/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4291 - accuracy: 0.4526 - val_loss: 1.5532 - val_accuracy: 0.5352\n",
      "Epoch 136/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4123 - accuracy: 0.4702 - val_loss: 1.5259 - val_accuracy: 0.5493\n",
      "Epoch 137/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4334 - accuracy: 0.4526 - val_loss: 1.5387 - val_accuracy: 0.5352\n",
      "Epoch 138/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4544 - accuracy: 0.4491 - val_loss: 1.5383 - val_accuracy: 0.5211\n",
      "Epoch 139/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4155 - accuracy: 0.4632 - val_loss: 1.5288 - val_accuracy: 0.5070\n",
      "Epoch 140/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.3929 - accuracy: 0.4772 - val_loss: 1.5362 - val_accuracy: 0.5352\n",
      "Epoch 141/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4231 - accuracy: 0.4632 - val_loss: 1.5338 - val_accuracy: 0.5352\n",
      "Epoch 142/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4376 - accuracy: 0.4842 - val_loss: 1.5117 - val_accuracy: 0.5070\n",
      "Epoch 143/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4569 - accuracy: 0.4491 - val_loss: 1.5029 - val_accuracy: 0.5493\n",
      "Epoch 144/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4613 - accuracy: 0.4596 - val_loss: 1.5186 - val_accuracy: 0.5070\n",
      "Epoch 145/170\n",
      "285/285 [==============================] - 0s 126us/step - loss: 1.4058 - accuracy: 0.4807 - val_loss: 1.5362 - val_accuracy: 0.5211\n",
      "Epoch 146/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4045 - accuracy: 0.4667 - val_loss: 1.5111 - val_accuracy: 0.5070\n",
      "Epoch 147/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4366 - accuracy: 0.4596 - val_loss: 1.5139 - val_accuracy: 0.5070\n",
      "Epoch 148/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4355 - accuracy: 0.4421 - val_loss: 1.5178 - val_accuracy: 0.5070\n",
      "Epoch 149/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.3857 - accuracy: 0.4912 - val_loss: 1.5155 - val_accuracy: 0.5352\n",
      "Epoch 150/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4376 - accuracy: 0.4596 - val_loss: 1.5383 - val_accuracy: 0.5493\n",
      "Epoch 151/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4080 - accuracy: 0.4807 - val_loss: 1.5216 - val_accuracy: 0.5070\n",
      "Epoch 152/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.3919 - accuracy: 0.4947 - val_loss: 1.5157 - val_accuracy: 0.5493\n",
      "Epoch 153/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4551 - accuracy: 0.4070 - val_loss: 1.5263 - val_accuracy: 0.5352\n",
      "Epoch 154/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4748 - accuracy: 0.4316 - val_loss: 1.5241 - val_accuracy: 0.4789\n",
      "Epoch 155/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4672 - accuracy: 0.4316 - val_loss: 1.5332 - val_accuracy: 0.5493\n",
      "Epoch 156/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.3877 - accuracy: 0.4842 - val_loss: 1.5012 - val_accuracy: 0.5211\n",
      "Epoch 157/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4039 - accuracy: 0.4737 - val_loss: 1.5199 - val_accuracy: 0.5493\n",
      "Epoch 158/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4303 - accuracy: 0.4561 - val_loss: 1.5040 - val_accuracy: 0.5211\n",
      "Epoch 159/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4073 - accuracy: 0.4702 - val_loss: 1.4925 - val_accuracy: 0.5352\n",
      "Epoch 160/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4073 - accuracy: 0.4561 - val_loss: 1.5267 - val_accuracy: 0.5070\n",
      "Epoch 161/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.3904 - accuracy: 0.4596 - val_loss: 1.5135 - val_accuracy: 0.5070\n",
      "Epoch 162/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.3846 - accuracy: 0.4772 - val_loss: 1.5047 - val_accuracy: 0.5070\n",
      "Epoch 163/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4417 - accuracy: 0.4842 - val_loss: 1.5016 - val_accuracy: 0.5211\n",
      "Epoch 164/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4069 - accuracy: 0.4632 - val_loss: 1.5006 - val_accuracy: 0.5352\n",
      "Epoch 165/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.3809 - accuracy: 0.4842 - val_loss: 1.5057 - val_accuracy: 0.5211\n",
      "Epoch 166/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.3970 - accuracy: 0.4737 - val_loss: 1.4954 - val_accuracy: 0.5211\n",
      "Epoch 167/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4274 - accuracy: 0.4667 - val_loss: 1.5046 - val_accuracy: 0.5070\n",
      "Epoch 168/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4214 - accuracy: 0.4526 - val_loss: 1.5104 - val_accuracy: 0.5211\n",
      "Epoch 169/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4448 - accuracy: 0.4386 - val_loss: 1.5049 - val_accuracy: 0.5070\n",
      "Epoch 170/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 1.3913 - accuracy: 0.4737 - val_loss: 1.4968 - val_accuracy: 0.5070\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 285 samples, validate on 71 samples\n",
      "Epoch 1/170\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 15.6333 - accuracy: 0.1474 - val_loss: 355.0817 - val_accuracy: 0.1831\n",
      "Epoch 2/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 11.7215 - accuracy: 0.1614 - val_loss: 300.1660 - val_accuracy: 0.1549\n",
      "Epoch 3/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 11.7775 - accuracy: 0.1333 - val_loss: 259.4204 - val_accuracy: 0.1690\n",
      "Epoch 4/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 9.4975 - accuracy: 0.1368 - val_loss: 228.6815 - val_accuracy: 0.2254\n",
      "Epoch 5/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 7.1232 - accuracy: 0.1404 - val_loss: 197.4656 - val_accuracy: 0.1268\n",
      "Epoch 6/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 5.3261 - accuracy: 0.1579 - val_loss: 160.5600 - val_accuracy: 0.1690\n",
      "Epoch 7/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 4.3745 - accuracy: 0.1965 - val_loss: 112.4084 - val_accuracy: 0.2958\n",
      "Epoch 8/170\n",
      "285/285 [==============================] - 0s 124us/step - loss: 2.6663 - accuracy: 0.2105 - val_loss: 83.3243 - val_accuracy: 0.2958\n",
      "Epoch 9/170\n",
      "285/285 [==============================] - 0s 122us/step - loss: 3.0326 - accuracy: 0.2351 - val_loss: 40.0387 - val_accuracy: 0.3239\n",
      "Epoch 10/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 2.0924 - accuracy: 0.2526 - val_loss: 31.7800 - val_accuracy: 0.3521\n",
      "Epoch 11/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 2.6047 - accuracy: 0.2702 - val_loss: 18.8846 - val_accuracy: 0.3380\n",
      "Epoch 12/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 3.7569 - accuracy: 0.2772 - val_loss: 14.8337 - val_accuracy: 0.3521\n",
      "Epoch 13/170\n",
      "285/285 [==============================] - 0s 122us/step - loss: 2.1930 - accuracy: 0.3123 - val_loss: 8.8315 - val_accuracy: 0.3521\n",
      "Epoch 14/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 2.5148 - accuracy: 0.2912 - val_loss: 5.8816 - val_accuracy: 0.3521\n",
      "Epoch 15/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.7122 - accuracy: 0.2912 - val_loss: 3.4855 - val_accuracy: 0.3380\n",
      "Epoch 16/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 2.9090 - accuracy: 0.2596 - val_loss: 2.3959 - val_accuracy: 0.3380\n",
      "Epoch 17/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.7192 - accuracy: 0.2842 - val_loss: 1.6645 - val_accuracy: 0.3380\n",
      "Epoch 18/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.7503 - accuracy: 0.2982 - val_loss: 1.6570 - val_accuracy: 0.3380\n",
      "Epoch 19/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.7021 - accuracy: 0.3018 - val_loss: 1.6547 - val_accuracy: 0.3380\n",
      "Epoch 20/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 2.1623 - accuracy: 0.2737 - val_loss: 1.6519 - val_accuracy: 0.3380\n",
      "Epoch 21/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.7718 - accuracy: 0.2807 - val_loss: 1.6693 - val_accuracy: 0.3380\n",
      "Epoch 22/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6881 - accuracy: 0.2912 - val_loss: 1.6565 - val_accuracy: 0.3380\n",
      "Epoch 23/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6758 - accuracy: 0.2982 - val_loss: 1.6490 - val_accuracy: 0.3380\n",
      "Epoch 24/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6645 - accuracy: 0.2947 - val_loss: 1.6434 - val_accuracy: 0.3380\n",
      "Epoch 25/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 2.0050 - accuracy: 0.3053 - val_loss: 1.6389 - val_accuracy: 0.3380\n",
      "Epoch 26/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.7388 - accuracy: 0.3123 - val_loss: 1.6380 - val_accuracy: 0.3380\n",
      "Epoch 27/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6614 - accuracy: 0.2947 - val_loss: 1.6668 - val_accuracy: 0.3380\n",
      "Epoch 28/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6596 - accuracy: 0.3263 - val_loss: 1.6516 - val_accuracy: 0.3380\n",
      "Epoch 29/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6699 - accuracy: 0.3088 - val_loss: 1.6561 - val_accuracy: 0.3380\n",
      "Epoch 30/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.8879 - accuracy: 0.3123 - val_loss: 1.6469 - val_accuracy: 0.3380\n",
      "Epoch 31/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6804 - accuracy: 0.3123 - val_loss: 1.6477 - val_accuracy: 0.3380\n",
      "Epoch 32/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6820 - accuracy: 0.3123 - val_loss: 1.6505 - val_accuracy: 0.3380\n",
      "Epoch 33/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6863 - accuracy: 0.2877 - val_loss: 1.6532 - val_accuracy: 0.3380\n",
      "Epoch 34/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6393 - accuracy: 0.3474 - val_loss: 1.6518 - val_accuracy: 0.3380\n",
      "Epoch 35/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6542 - accuracy: 0.2842 - val_loss: 1.6413 - val_accuracy: 0.3380\n",
      "Epoch 36/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6715 - accuracy: 0.3123 - val_loss: 1.6379 - val_accuracy: 0.3380\n",
      "Epoch 37/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6632 - accuracy: 0.3158 - val_loss: 1.6344 - val_accuracy: 0.3380\n",
      "Epoch 38/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6459 - accuracy: 0.3228 - val_loss: 1.6442 - val_accuracy: 0.3380\n",
      "Epoch 39/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.6595 - accuracy: 0.2842 - val_loss: 1.6247 - val_accuracy: 0.3380\n",
      "Epoch 40/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6549 - accuracy: 0.3018 - val_loss: 1.6237 - val_accuracy: 0.3380\n",
      "Epoch 41/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6556 - accuracy: 0.3053 - val_loss: 1.6206 - val_accuracy: 0.3380\n",
      "Epoch 42/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6578 - accuracy: 0.3123 - val_loss: 1.6177 - val_accuracy: 0.3380\n",
      "Epoch 43/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6618 - accuracy: 0.2982 - val_loss: 1.6277 - val_accuracy: 0.3380\n",
      "Epoch 44/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.8769 - accuracy: 0.3123 - val_loss: 1.5771 - val_accuracy: 0.3380\n",
      "Epoch 45/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7341 - accuracy: 0.3088 - val_loss: 1.5824 - val_accuracy: 0.3380\n",
      "Epoch 46/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6607 - accuracy: 0.3298 - val_loss: 1.6496 - val_accuracy: 0.3380\n",
      "Epoch 47/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6679 - accuracy: 0.3088 - val_loss: 1.6708 - val_accuracy: 0.3521\n",
      "Epoch 48/170\n",
      "285/285 [==============================] - 0s 124us/step - loss: 1.6286 - accuracy: 0.3228 - val_loss: 1.6879 - val_accuracy: 0.3521\n",
      "Epoch 49/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6743 - accuracy: 0.3404 - val_loss: 1.7201 - val_accuracy: 0.3521\n",
      "Epoch 50/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.7037 - accuracy: 0.3193 - val_loss: 1.6957 - val_accuracy: 0.3521\n",
      "Epoch 51/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6250 - accuracy: 0.3088 - val_loss: 1.7031 - val_accuracy: 0.3521\n",
      "Epoch 52/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6340 - accuracy: 0.3053 - val_loss: 1.7340 - val_accuracy: 0.3521\n",
      "Epoch 53/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.6125 - accuracy: 0.3298 - val_loss: 1.7711 - val_accuracy: 0.3521\n",
      "Epoch 54/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6115 - accuracy: 0.3158 - val_loss: 1.7941 - val_accuracy: 0.3521\n",
      "Epoch 55/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6624 - accuracy: 0.3333 - val_loss: 1.7861 - val_accuracy: 0.3521\n",
      "Epoch 56/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6268 - accuracy: 0.3263 - val_loss: 1.7856 - val_accuracy: 0.3521\n",
      "Epoch 57/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6796 - accuracy: 0.3123 - val_loss: 1.7804 - val_accuracy: 0.3521\n",
      "Epoch 58/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.6329 - accuracy: 0.3158 - val_loss: 1.7693 - val_accuracy: 0.3521\n",
      "Epoch 59/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.6485 - accuracy: 0.3368 - val_loss: 1.7606 - val_accuracy: 0.3521\n",
      "Epoch 60/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6283 - accuracy: 0.3123 - val_loss: 1.7574 - val_accuracy: 0.3521\n",
      "Epoch 61/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.6594 - accuracy: 0.3123 - val_loss: 1.7534 - val_accuracy: 0.3521\n",
      "Epoch 62/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6757 - accuracy: 0.3123 - val_loss: 1.7423 - val_accuracy: 0.3521\n",
      "Epoch 63/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6469 - accuracy: 0.3298 - val_loss: 1.7184 - val_accuracy: 0.3521\n",
      "Epoch 64/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6584 - accuracy: 0.3158 - val_loss: 1.7116 - val_accuracy: 0.3521\n",
      "Epoch 65/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6443 - accuracy: 0.3088 - val_loss: 1.6477 - val_accuracy: 0.3380\n",
      "Epoch 66/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6434 - accuracy: 0.3088 - val_loss: 1.6391 - val_accuracy: 0.3380\n",
      "Epoch 67/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.6496 - accuracy: 0.3193 - val_loss: 1.6845 - val_accuracy: 0.3380\n",
      "Epoch 68/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6556 - accuracy: 0.3053 - val_loss: 1.6997 - val_accuracy: 0.3380\n",
      "Epoch 69/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6518 - accuracy: 0.3193 - val_loss: 1.6975 - val_accuracy: 0.3380\n",
      "Epoch 70/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6344 - accuracy: 0.3158 - val_loss: 1.7234 - val_accuracy: 0.3521\n",
      "Epoch 71/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6397 - accuracy: 0.3158 - val_loss: 1.7292 - val_accuracy: 0.3521\n",
      "Epoch 72/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6351 - accuracy: 0.3123 - val_loss: 1.7485 - val_accuracy: 0.3521\n",
      "Epoch 73/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6283 - accuracy: 0.3333 - val_loss: 1.7614 - val_accuracy: 0.3521\n",
      "Epoch 74/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.6385 - accuracy: 0.3298 - val_loss: 1.7535 - val_accuracy: 0.3521\n",
      "Epoch 75/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6479 - accuracy: 0.3228 - val_loss: 1.7612 - val_accuracy: 0.3521\n",
      "Epoch 76/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6261 - accuracy: 0.3088 - val_loss: 1.7691 - val_accuracy: 0.3521\n",
      "Epoch 77/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6293 - accuracy: 0.3088 - val_loss: 1.7824 - val_accuracy: 0.3521\n",
      "Epoch 78/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6529 - accuracy: 0.3228 - val_loss: 1.7699 - val_accuracy: 0.3521\n",
      "Epoch 79/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6383 - accuracy: 0.3228 - val_loss: 1.7655 - val_accuracy: 0.3521\n",
      "Epoch 80/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6641 - accuracy: 0.2702 - val_loss: 1.7636 - val_accuracy: 0.3521\n",
      "Epoch 81/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6368 - accuracy: 0.3123 - val_loss: 1.6941 - val_accuracy: 0.3380\n",
      "Epoch 82/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.6242 - accuracy: 0.3368 - val_loss: 1.6968 - val_accuracy: 0.3380\n",
      "Epoch 83/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6270 - accuracy: 0.3298 - val_loss: 1.6932 - val_accuracy: 0.3380\n",
      "Epoch 84/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6465 - accuracy: 0.3228 - val_loss: 1.7011 - val_accuracy: 0.3521\n",
      "Epoch 85/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6128 - accuracy: 0.3333 - val_loss: 1.7137 - val_accuracy: 0.3521\n",
      "Epoch 86/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6373 - accuracy: 0.3298 - val_loss: 1.7279 - val_accuracy: 0.3521\n",
      "Epoch 87/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6418 - accuracy: 0.3263 - val_loss: 1.7256 - val_accuracy: 0.3521\n",
      "Epoch 88/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6294 - accuracy: 0.3158 - val_loss: 1.7432 - val_accuracy: 0.3521\n",
      "Epoch 89/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6315 - accuracy: 0.3158 - val_loss: 1.7600 - val_accuracy: 0.3521\n",
      "Epoch 90/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6365 - accuracy: 0.3053 - val_loss: 1.7644 - val_accuracy: 0.3521\n",
      "Epoch 91/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6490 - accuracy: 0.3088 - val_loss: 1.7429 - val_accuracy: 0.3521\n",
      "Epoch 92/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6074 - accuracy: 0.3228 - val_loss: 1.7577 - val_accuracy: 0.3521\n",
      "Epoch 93/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6692 - accuracy: 0.3018 - val_loss: 1.7656 - val_accuracy: 0.3521\n",
      "Epoch 94/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6122 - accuracy: 0.3298 - val_loss: 1.7698 - val_accuracy: 0.3521\n",
      "Epoch 95/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6278 - accuracy: 0.3333 - val_loss: 1.7591 - val_accuracy: 0.3521\n",
      "Epoch 96/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.6025 - accuracy: 0.3193 - val_loss: 1.7928 - val_accuracy: 0.3521\n",
      "Epoch 97/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.6112 - accuracy: 0.3509 - val_loss: 1.8161 - val_accuracy: 0.3521\n",
      "Epoch 98/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.6331 - accuracy: 0.3123 - val_loss: 1.7923 - val_accuracy: 0.3662\n",
      "Epoch 99/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6018 - accuracy: 0.3263 - val_loss: 1.7867 - val_accuracy: 0.3944\n",
      "Epoch 100/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5961 - accuracy: 0.4000 - val_loss: 1.7887 - val_accuracy: 0.4225\n",
      "Epoch 101/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5628 - accuracy: 0.4175 - val_loss: 1.7775 - val_accuracy: 0.4507\n",
      "Epoch 102/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5832 - accuracy: 0.3754 - val_loss: 1.7997 - val_accuracy: 0.4366\n",
      "Epoch 103/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5630 - accuracy: 0.4175 - val_loss: 1.7918 - val_accuracy: 0.4507\n",
      "Epoch 104/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5564 - accuracy: 0.4421 - val_loss: 1.7899 - val_accuracy: 0.4507\n",
      "Epoch 105/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5217 - accuracy: 0.4316 - val_loss: 1.7922 - val_accuracy: 0.4507\n",
      "Epoch 106/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5134 - accuracy: 0.4596 - val_loss: 1.8297 - val_accuracy: 0.4225\n",
      "Epoch 107/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5705 - accuracy: 0.4316 - val_loss: 1.8064 - val_accuracy: 0.4507\n",
      "Epoch 108/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5653 - accuracy: 0.4000 - val_loss: 1.7737 - val_accuracy: 0.4648\n",
      "Epoch 109/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5215 - accuracy: 0.4456 - val_loss: 1.7553 - val_accuracy: 0.4507\n",
      "Epoch 110/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5325 - accuracy: 0.4456 - val_loss: 1.7546 - val_accuracy: 0.4507\n",
      "Epoch 111/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5089 - accuracy: 0.4351 - val_loss: 1.7532 - val_accuracy: 0.4507\n",
      "Epoch 112/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5533 - accuracy: 0.4246 - val_loss: 1.7995 - val_accuracy: 0.4225\n",
      "Epoch 113/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6174 - accuracy: 0.3895 - val_loss: 1.7315 - val_accuracy: 0.4507\n",
      "Epoch 114/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5200 - accuracy: 0.4386 - val_loss: 1.7395 - val_accuracy: 0.4507\n",
      "Epoch 115/170\n",
      "285/285 [==============================] - 0s 121us/step - loss: 1.5161 - accuracy: 0.4316 - val_loss: 1.7685 - val_accuracy: 0.4507\n",
      "Epoch 116/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5212 - accuracy: 0.4526 - val_loss: 1.8229 - val_accuracy: 0.4225\n",
      "Epoch 117/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5375 - accuracy: 0.4386 - val_loss: 1.7351 - val_accuracy: 0.4648\n",
      "Epoch 118/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5246 - accuracy: 0.4386 - val_loss: 1.7361 - val_accuracy: 0.4507\n",
      "Epoch 119/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5140 - accuracy: 0.4526 - val_loss: 1.7645 - val_accuracy: 0.4366\n",
      "Epoch 120/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5055 - accuracy: 0.4491 - val_loss: 1.7308 - val_accuracy: 0.4648\n",
      "Epoch 121/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.4760 - accuracy: 0.4421 - val_loss: 1.7566 - val_accuracy: 0.4648\n",
      "Epoch 122/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.4797 - accuracy: 0.4491 - val_loss: 1.7688 - val_accuracy: 0.4507\n",
      "Epoch 123/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5067 - accuracy: 0.4281 - val_loss: 1.7826 - val_accuracy: 0.4648\n",
      "Epoch 124/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4887 - accuracy: 0.4246 - val_loss: 1.8354 - val_accuracy: 0.4366\n",
      "Epoch 125/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5189 - accuracy: 0.4421 - val_loss: 1.8044 - val_accuracy: 0.4648\n",
      "Epoch 126/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.4598 - accuracy: 0.4667 - val_loss: 1.7758 - val_accuracy: 0.4648\n",
      "Epoch 127/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4552 - accuracy: 0.4632 - val_loss: 1.7740 - val_accuracy: 0.4366\n",
      "Epoch 128/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5357 - accuracy: 0.4246 - val_loss: 1.7501 - val_accuracy: 0.4366\n",
      "Epoch 129/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5445 - accuracy: 0.4035 - val_loss: 1.7394 - val_accuracy: 0.4648\n",
      "Epoch 130/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4877 - accuracy: 0.4526 - val_loss: 1.7647 - val_accuracy: 0.4366\n",
      "Epoch 131/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4754 - accuracy: 0.4596 - val_loss: 1.7470 - val_accuracy: 0.4648\n",
      "Epoch 132/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4740 - accuracy: 0.4596 - val_loss: 1.7702 - val_accuracy: 0.4648\n",
      "Epoch 133/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.4705 - accuracy: 0.4456 - val_loss: 1.7523 - val_accuracy: 0.4648\n",
      "Epoch 134/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.4867 - accuracy: 0.4351 - val_loss: 1.7454 - val_accuracy: 0.4648\n",
      "Epoch 135/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.4775 - accuracy: 0.4561 - val_loss: 1.7887 - val_accuracy: 0.4366\n",
      "Epoch 136/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4937 - accuracy: 0.4456 - val_loss: 1.7430 - val_accuracy: 0.4648\n",
      "Epoch 137/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4892 - accuracy: 0.4491 - val_loss: 1.7325 - val_accuracy: 0.4507\n",
      "Epoch 138/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5346 - accuracy: 0.4281 - val_loss: 1.7408 - val_accuracy: 0.4507\n",
      "Epoch 139/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4385 - accuracy: 0.4596 - val_loss: 1.7561 - val_accuracy: 0.4507\n",
      "Epoch 140/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4638 - accuracy: 0.4526 - val_loss: 1.7447 - val_accuracy: 0.4648\n",
      "Epoch 141/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5011 - accuracy: 0.4316 - val_loss: 1.7670 - val_accuracy: 0.4648\n",
      "Epoch 142/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4784 - accuracy: 0.4456 - val_loss: 1.7987 - val_accuracy: 0.4648\n",
      "Epoch 143/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4668 - accuracy: 0.4491 - val_loss: 1.8124 - val_accuracy: 0.4648\n",
      "Epoch 144/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4568 - accuracy: 0.4526 - val_loss: 1.7922 - val_accuracy: 0.4648\n",
      "Epoch 145/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.4746 - accuracy: 0.4421 - val_loss: 1.7563 - val_accuracy: 0.4648\n",
      "Epoch 146/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.4997 - accuracy: 0.4456 - val_loss: 1.7480 - val_accuracy: 0.4648\n",
      "Epoch 147/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.4836 - accuracy: 0.4491 - val_loss: 1.7445 - val_accuracy: 0.4648\n",
      "Epoch 148/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.4489 - accuracy: 0.4632 - val_loss: 1.8058 - val_accuracy: 0.4225\n",
      "Epoch 149/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5278 - accuracy: 0.4281 - val_loss: 1.7493 - val_accuracy: 0.4648\n",
      "Epoch 150/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5100 - accuracy: 0.4421 - val_loss: 1.7208 - val_accuracy: 0.4648\n",
      "Epoch 151/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4576 - accuracy: 0.4596 - val_loss: 1.7774 - val_accuracy: 0.4366\n",
      "Epoch 152/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4911 - accuracy: 0.4491 - val_loss: 1.7061 - val_accuracy: 0.4648\n",
      "Epoch 153/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4353 - accuracy: 0.4421 - val_loss: 1.7371 - val_accuracy: 0.4648\n",
      "Epoch 154/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4312 - accuracy: 0.4596 - val_loss: 1.7765 - val_accuracy: 0.4648\n",
      "Epoch 155/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4579 - accuracy: 0.4491 - val_loss: 1.7518 - val_accuracy: 0.4648\n",
      "Epoch 156/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5043 - accuracy: 0.4281 - val_loss: 1.7303 - val_accuracy: 0.4648\n",
      "Epoch 157/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.4628 - accuracy: 0.4596 - val_loss: 1.7549 - val_accuracy: 0.4366\n",
      "Epoch 158/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4730 - accuracy: 0.4526 - val_loss: 1.7468 - val_accuracy: 0.4648\n",
      "Epoch 159/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.4834 - accuracy: 0.4246 - val_loss: 1.7272 - val_accuracy: 0.4648\n",
      "Epoch 160/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.4651 - accuracy: 0.4526 - val_loss: 1.7767 - val_accuracy: 0.4366\n",
      "Epoch 161/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4690 - accuracy: 0.4526 - val_loss: 1.7655 - val_accuracy: 0.4789\n",
      "Epoch 162/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4667 - accuracy: 0.4491 - val_loss: 1.7045 - val_accuracy: 0.4648\n",
      "Epoch 163/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.4856 - accuracy: 0.4351 - val_loss: 1.6997 - val_accuracy: 0.4648\n",
      "Epoch 164/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4432 - accuracy: 0.4702 - val_loss: 1.6622 - val_accuracy: 0.4648\n",
      "Epoch 165/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4915 - accuracy: 0.4421 - val_loss: 1.6587 - val_accuracy: 0.4648\n",
      "Epoch 166/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.4395 - accuracy: 0.4702 - val_loss: 1.6455 - val_accuracy: 0.4648\n",
      "Epoch 167/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4158 - accuracy: 0.4596 - val_loss: 1.6521 - val_accuracy: 0.4648\n",
      "Epoch 168/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4629 - accuracy: 0.4456 - val_loss: 1.6920 - val_accuracy: 0.4648\n",
      "Epoch 169/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.4714 - accuracy: 0.4526 - val_loss: 1.6882 - val_accuracy: 0.4648\n",
      "Epoch 170/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4594 - accuracy: 0.4491 - val_loss: 1.6757 - val_accuracy: 0.4789\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 285 samples, validate on 71 samples\n",
      "Epoch 1/170\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 35.4187 - accuracy: 0.2421 - val_loss: 5.6869 - val_accuracy: 0.0986\n",
      "Epoch 2/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 42.9412 - accuracy: 0.1719 - val_loss: 2.6389 - val_accuracy: 0.2817\n",
      "Epoch 3/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 9.0726 - accuracy: 0.2386 - val_loss: 2.1283 - val_accuracy: 0.1972\n",
      "Epoch 4/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 14.3046 - accuracy: 0.2386 - val_loss: 1.8934 - val_accuracy: 0.1549\n",
      "Epoch 5/170\n",
      "285/285 [==============================] - 0s 125us/step - loss: 6.2179 - accuracy: 0.2035 - val_loss: 1.7627 - val_accuracy: 0.1972\n",
      "Epoch 6/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 5.2100 - accuracy: 0.2421 - val_loss: 1.7873 - val_accuracy: 0.2254\n",
      "Epoch 7/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 5.3881 - accuracy: 0.2421 - val_loss: 1.7581 - val_accuracy: 0.2535\n",
      "Epoch 8/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 23.4896 - accuracy: 0.2491 - val_loss: 1.6980 - val_accuracy: 0.3521\n",
      "Epoch 9/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 7.1227 - accuracy: 0.2807 - val_loss: 1.7058 - val_accuracy: 0.2535\n",
      "Epoch 10/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 2.9245 - accuracy: 0.2561 - val_loss: 1.6304 - val_accuracy: 0.3239\n",
      "Epoch 11/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 2.9235 - accuracy: 0.3018 - val_loss: 1.5964 - val_accuracy: 0.3803\n",
      "Epoch 12/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 3.0281 - accuracy: 0.3123 - val_loss: 1.6240 - val_accuracy: 0.3521\n",
      "Epoch 13/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 4.6018 - accuracy: 0.3053 - val_loss: 1.6652 - val_accuracy: 0.2817\n",
      "Epoch 14/170\n",
      "285/285 [==============================] - 0s 121us/step - loss: 3.7332 - accuracy: 0.2877 - val_loss: 1.6705 - val_accuracy: 0.3803\n",
      "Epoch 15/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 2.7625 - accuracy: 0.3123 - val_loss: 1.7361 - val_accuracy: 0.2676\n",
      "Epoch 16/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 4.4817 - accuracy: 0.3228 - val_loss: 1.6852 - val_accuracy: 0.4085\n",
      "Epoch 17/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 5.5318 - accuracy: 0.3930 - val_loss: 1.6794 - val_accuracy: 0.3803\n",
      "Epoch 18/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.9817 - accuracy: 0.2737 - val_loss: 1.6715 - val_accuracy: 0.3239\n",
      "Epoch 19/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 2.3580 - accuracy: 0.2737 - val_loss: 1.6744 - val_accuracy: 0.2535\n",
      "Epoch 20/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 2.5526 - accuracy: 0.2842 - val_loss: 1.6621 - val_accuracy: 0.3099\n",
      "Epoch 21/170\n",
      "285/285 [==============================] - 0s 128us/step - loss: 3.4128 - accuracy: 0.2877 - val_loss: 1.6594 - val_accuracy: 0.3380\n",
      "Epoch 22/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 2.0276 - accuracy: 0.3088 - val_loss: 1.6826 - val_accuracy: 0.3239\n",
      "Epoch 23/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 2.3537 - accuracy: 0.2982 - val_loss: 1.7080 - val_accuracy: 0.3380\n",
      "Epoch 24/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 2.1867 - accuracy: 0.3018 - val_loss: 1.6909 - val_accuracy: 0.3803\n",
      "Epoch 25/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 3.3850 - accuracy: 0.3018 - val_loss: 1.6651 - val_accuracy: 0.3521\n",
      "Epoch 26/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.8968 - accuracy: 0.3158 - val_loss: 1.6802 - val_accuracy: 0.2817\n",
      "Epoch 27/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 4.1521 - accuracy: 0.2772 - val_loss: 1.6792 - val_accuracy: 0.3380\n",
      "Epoch 28/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 2.1208 - accuracy: 0.2737 - val_loss: 1.6954 - val_accuracy: 0.2817\n",
      "Epoch 29/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 2.6303 - accuracy: 0.3123 - val_loss: 1.6809 - val_accuracy: 0.4507\n",
      "Epoch 30/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.8509 - accuracy: 0.3193 - val_loss: 1.6760 - val_accuracy: 0.4648\n",
      "Epoch 31/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 3.8509 - accuracy: 0.3368 - val_loss: 1.6763 - val_accuracy: 0.4366\n",
      "Epoch 32/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 9.2591 - accuracy: 0.3754 - val_loss: 1.6293 - val_accuracy: 0.3803\n",
      "Epoch 33/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.8863 - accuracy: 0.3965 - val_loss: 1.6413 - val_accuracy: 0.4085\n",
      "Epoch 34/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 3.5739 - accuracy: 0.3965 - val_loss: 1.6202 - val_accuracy: 0.4085\n",
      "Epoch 35/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 2.0679 - accuracy: 0.3614 - val_loss: 1.6122 - val_accuracy: 0.3803\n",
      "Epoch 36/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.9696 - accuracy: 0.3614 - val_loss: 1.6134 - val_accuracy: 0.4366\n",
      "Epoch 37/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 4.3882 - accuracy: 0.3544 - val_loss: 1.6142 - val_accuracy: 0.4507\n",
      "Epoch 38/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 14.5247 - accuracy: 0.3684 - val_loss: 1.6645 - val_accuracy: 0.3944\n",
      "Epoch 39/170\n",
      "285/285 [==============================] - 0s 122us/step - loss: 2.1679 - accuracy: 0.3825 - val_loss: 1.6525 - val_accuracy: 0.4366\n",
      "Epoch 40/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 3.2134 - accuracy: 0.3439 - val_loss: 1.6658 - val_accuracy: 0.3944\n",
      "Epoch 41/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.3045 - accuracy: 0.4246 - val_loss: 1.6475 - val_accuracy: 0.4507\n",
      "Epoch 42/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6932 - accuracy: 0.3754 - val_loss: 1.6486 - val_accuracy: 0.4507\n",
      "Epoch 43/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 3.3727 - accuracy: 0.4035 - val_loss: 1.6562 - val_accuracy: 0.4225\n",
      "Epoch 44/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6258 - accuracy: 0.3825 - val_loss: 1.6423 - val_accuracy: 0.4507\n",
      "Epoch 45/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 2.0943 - accuracy: 0.3789 - val_loss: 1.6283 - val_accuracy: 0.3662\n",
      "Epoch 46/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 2.2178 - accuracy: 0.3789 - val_loss: 1.6288 - val_accuracy: 0.3944\n",
      "Epoch 47/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.3484 - accuracy: 0.3825 - val_loss: 1.6330 - val_accuracy: 0.3944\n",
      "Epoch 48/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 3.0626 - accuracy: 0.3825 - val_loss: 1.6624 - val_accuracy: 0.4225\n",
      "Epoch 49/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 3.0467 - accuracy: 0.3719 - val_loss: 1.6589 - val_accuracy: 0.4507\n",
      "Epoch 50/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 2.2878 - accuracy: 0.3825 - val_loss: 1.6496 - val_accuracy: 0.4507\n",
      "Epoch 51/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.7918 - accuracy: 0.3509 - val_loss: 1.6404 - val_accuracy: 0.4366\n",
      "Epoch 52/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.6203 - accuracy: 0.3860 - val_loss: 1.6430 - val_accuracy: 0.4085\n",
      "Epoch 53/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.8731 - accuracy: 0.3754 - val_loss: 1.6306 - val_accuracy: 0.4366\n",
      "Epoch 54/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5594 - accuracy: 0.3789 - val_loss: 1.6325 - val_accuracy: 0.3944\n",
      "Epoch 55/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6129 - accuracy: 0.3860 - val_loss: 1.6448 - val_accuracy: 0.3944\n",
      "Epoch 56/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5142 - accuracy: 0.4175 - val_loss: 1.6286 - val_accuracy: 0.4648\n",
      "Epoch 57/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 2.4373 - accuracy: 0.3649 - val_loss: 1.6243 - val_accuracy: 0.4225\n",
      "Epoch 58/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.7069 - accuracy: 0.4246 - val_loss: 1.5956 - val_accuracy: 0.4648\n",
      "Epoch 59/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 2.0011 - accuracy: 0.3965 - val_loss: 1.5921 - val_accuracy: 0.4507\n",
      "Epoch 60/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 2.0052 - accuracy: 0.3649 - val_loss: 1.5908 - val_accuracy: 0.3944\n",
      "Epoch 61/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5748 - accuracy: 0.3719 - val_loss: 1.5987 - val_accuracy: 0.3944\n",
      "Epoch 62/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.5787 - accuracy: 0.4035 - val_loss: 1.6150 - val_accuracy: 0.4225\n",
      "Epoch 63/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.0277 - accuracy: 0.4140 - val_loss: 1.6063 - val_accuracy: 0.4366\n",
      "Epoch 64/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.5969 - accuracy: 0.4070 - val_loss: 1.6177 - val_accuracy: 0.4507\n",
      "Epoch 65/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.7065 - accuracy: 0.3474 - val_loss: 1.5974 - val_accuracy: 0.4225\n",
      "Epoch 66/170\n",
      "285/285 [==============================] - 0s 121us/step - loss: 1.6039 - accuracy: 0.4070 - val_loss: 1.5968 - val_accuracy: 0.4225\n",
      "Epoch 67/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 4.1071 - accuracy: 0.3684 - val_loss: 1.5778 - val_accuracy: 0.4085\n",
      "Epoch 68/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.8960 - accuracy: 0.3895 - val_loss: 1.5461 - val_accuracy: 0.4225\n",
      "Epoch 69/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.0110 - accuracy: 0.3860 - val_loss: 1.5623 - val_accuracy: 0.3944\n",
      "Epoch 70/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.6528 - accuracy: 0.4175 - val_loss: 1.5652 - val_accuracy: 0.4648\n",
      "Epoch 71/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 7.1893 - accuracy: 0.4035 - val_loss: 1.5503 - val_accuracy: 0.4366\n",
      "Epoch 72/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6616 - accuracy: 0.4140 - val_loss: 1.5523 - val_accuracy: 0.4085\n",
      "Epoch 73/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.6627 - accuracy: 0.3474 - val_loss: 1.5534 - val_accuracy: 0.4507\n",
      "Epoch 74/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.9824 - accuracy: 0.3825 - val_loss: 1.5607 - val_accuracy: 0.4225\n",
      "Epoch 75/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5767 - accuracy: 0.3930 - val_loss: 1.5617 - val_accuracy: 0.4366\n",
      "Epoch 76/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.9576 - accuracy: 0.3930 - val_loss: 1.5659 - val_accuracy: 0.3944\n",
      "Epoch 77/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 2.4948 - accuracy: 0.3544 - val_loss: 1.7301 - val_accuracy: 0.3662\n",
      "Epoch 78/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 2.6042 - accuracy: 0.3123 - val_loss: 1.5769 - val_accuracy: 0.3944\n",
      "Epoch 79/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.9884 - accuracy: 0.3404 - val_loss: 1.5988 - val_accuracy: 0.4225\n",
      "Epoch 80/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 2.8446 - accuracy: 0.3684 - val_loss: 1.5708 - val_accuracy: 0.3521\n",
      "Epoch 81/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.6777 - accuracy: 0.3825 - val_loss: 1.5356 - val_accuracy: 0.3944\n",
      "Epoch 82/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.7795 - accuracy: 0.3404 - val_loss: 1.5472 - val_accuracy: 0.4085\n",
      "Epoch 83/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 2.0977 - accuracy: 0.4070 - val_loss: 1.6915 - val_accuracy: 0.3944\n",
      "Epoch 84/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 4.0809 - accuracy: 0.3719 - val_loss: 1.8279 - val_accuracy: 0.4225\n",
      "Epoch 85/170\n",
      "285/285 [==============================] - 0s 123us/step - loss: 2.3616 - accuracy: 0.3789 - val_loss: 1.5898 - val_accuracy: 0.3662\n",
      "Epoch 86/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6233 - accuracy: 0.2772 - val_loss: 1.5766 - val_accuracy: 0.3521\n",
      "Epoch 87/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.6092 - accuracy: 0.3158 - val_loss: 1.5586 - val_accuracy: 0.3803\n",
      "Epoch 88/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5994 - accuracy: 0.3088 - val_loss: 1.5645 - val_accuracy: 0.3521\n",
      "Epoch 89/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5983 - accuracy: 0.3088 - val_loss: 1.5552 - val_accuracy: 0.3521\n",
      "Epoch 90/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.6023 - accuracy: 0.3088 - val_loss: 1.5616 - val_accuracy: 0.3662\n",
      "Epoch 91/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.6060 - accuracy: 0.2877 - val_loss: 1.5690 - val_accuracy: 0.3662\n",
      "Epoch 92/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5958 - accuracy: 0.3018 - val_loss: 1.5699 - val_accuracy: 0.3662\n",
      "Epoch 93/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5745 - accuracy: 0.3333 - val_loss: 1.5558 - val_accuracy: 0.3803\n",
      "Epoch 94/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5780 - accuracy: 0.3158 - val_loss: 1.5417 - val_accuracy: 0.3803\n",
      "Epoch 95/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5761 - accuracy: 0.3123 - val_loss: 1.5488 - val_accuracy: 0.3803\n",
      "Epoch 96/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5749 - accuracy: 0.3193 - val_loss: 1.5510 - val_accuracy: 0.3521\n",
      "Epoch 97/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5963 - accuracy: 0.3018 - val_loss: 1.5461 - val_accuracy: 0.3662\n",
      "Epoch 98/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5483 - accuracy: 0.3228 - val_loss: 1.5353 - val_accuracy: 0.3662\n",
      "Epoch 99/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5852 - accuracy: 0.2947 - val_loss: 1.5400 - val_accuracy: 0.4225\n",
      "Epoch 100/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5774 - accuracy: 0.3088 - val_loss: 1.5379 - val_accuracy: 0.3803\n",
      "Epoch 101/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5659 - accuracy: 0.3053 - val_loss: 1.5309 - val_accuracy: 0.3521\n",
      "Epoch 102/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5456 - accuracy: 0.3123 - val_loss: 1.5176 - val_accuracy: 0.3803\n",
      "Epoch 103/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5515 - accuracy: 0.3018 - val_loss: 1.5070 - val_accuracy: 0.3662\n",
      "Epoch 104/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5766 - accuracy: 0.3053 - val_loss: 1.5112 - val_accuracy: 0.3803\n",
      "Epoch 105/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5652 - accuracy: 0.3053 - val_loss: 1.5171 - val_accuracy: 0.4085\n",
      "Epoch 106/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5613 - accuracy: 0.3228 - val_loss: 1.5376 - val_accuracy: 0.3803\n",
      "Epoch 107/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5716 - accuracy: 0.3123 - val_loss: 1.5315 - val_accuracy: 0.3944\n",
      "Epoch 108/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5653 - accuracy: 0.3123 - val_loss: 1.5294 - val_accuracy: 0.3944\n",
      "Epoch 109/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5526 - accuracy: 0.3228 - val_loss: 1.5215 - val_accuracy: 0.3944\n",
      "Epoch 110/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5505 - accuracy: 0.3298 - val_loss: 1.5075 - val_accuracy: 0.4225\n",
      "Epoch 111/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5412 - accuracy: 0.3298 - val_loss: 1.5007 - val_accuracy: 0.4648\n",
      "Epoch 112/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5288 - accuracy: 0.4070 - val_loss: 1.5157 - val_accuracy: 0.4648\n",
      "Epoch 113/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.5738 - accuracy: 0.3544 - val_loss: 1.5185 - val_accuracy: 0.4366\n",
      "Epoch 114/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5372 - accuracy: 0.3895 - val_loss: 1.5017 - val_accuracy: 0.4648\n",
      "Epoch 115/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5542 - accuracy: 0.3719 - val_loss: 1.4978 - val_accuracy: 0.4507\n",
      "Epoch 116/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5133 - accuracy: 0.4281 - val_loss: 1.5013 - val_accuracy: 0.4225\n",
      "Epoch 117/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5801 - accuracy: 0.3544 - val_loss: 1.5095 - val_accuracy: 0.4930\n",
      "Epoch 118/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5106 - accuracy: 0.4211 - val_loss: 1.4953 - val_accuracy: 0.4085\n",
      "Epoch 119/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5285 - accuracy: 0.4000 - val_loss: 1.4859 - val_accuracy: 0.4507\n",
      "Epoch 120/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4884 - accuracy: 0.4632 - val_loss: 1.4732 - val_accuracy: 0.4085\n",
      "Epoch 121/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5001 - accuracy: 0.4316 - val_loss: 1.4819 - val_accuracy: 0.4225\n",
      "Epoch 122/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5466 - accuracy: 0.4105 - val_loss: 1.4784 - val_accuracy: 0.4789\n",
      "Epoch 123/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4795 - accuracy: 0.4491 - val_loss: 1.4754 - val_accuracy: 0.4366\n",
      "Epoch 124/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5025 - accuracy: 0.4386 - val_loss: 1.4680 - val_accuracy: 0.4648\n",
      "Epoch 125/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5707 - accuracy: 0.3930 - val_loss: 1.4826 - val_accuracy: 0.4789\n",
      "Epoch 126/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5006 - accuracy: 0.4491 - val_loss: 1.4844 - val_accuracy: 0.4648\n",
      "Epoch 127/170\n",
      "285/285 [==============================] - 0s 119us/step - loss: 1.5787 - accuracy: 0.3649 - val_loss: 1.4829 - val_accuracy: 0.5070\n",
      "Epoch 128/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4905 - accuracy: 0.4421 - val_loss: 1.4609 - val_accuracy: 0.4930\n",
      "Epoch 129/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.4923 - accuracy: 0.4175 - val_loss: 1.4710 - val_accuracy: 0.4507\n",
      "Epoch 130/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4959 - accuracy: 0.4316 - val_loss: 1.4865 - val_accuracy: 0.4648\n",
      "Epoch 131/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5107 - accuracy: 0.4281 - val_loss: 1.4406 - val_accuracy: 0.4930\n",
      "Epoch 132/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5581 - accuracy: 0.4632 - val_loss: 1.4779 - val_accuracy: 0.4930\n",
      "Epoch 133/170\n",
      "285/285 [==============================] - 0s 121us/step - loss: 1.5399 - accuracy: 0.4035 - val_loss: 1.4718 - val_accuracy: 0.4648\n",
      "Epoch 134/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5523 - accuracy: 0.4035 - val_loss: 1.4712 - val_accuracy: 0.4507\n",
      "Epoch 135/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5025 - accuracy: 0.4316 - val_loss: 1.4627 - val_accuracy: 0.4225\n",
      "Epoch 136/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.5059 - accuracy: 0.3965 - val_loss: 1.4627 - val_accuracy: 0.4648\n",
      "Epoch 137/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5190 - accuracy: 0.4316 - val_loss: 1.4776 - val_accuracy: 0.4366\n",
      "Epoch 138/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5031 - accuracy: 0.3930 - val_loss: 1.4645 - val_accuracy: 0.4507\n",
      "Epoch 139/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5153 - accuracy: 0.4140 - val_loss: 1.4695 - val_accuracy: 0.4930\n",
      "Epoch 140/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.5256 - accuracy: 0.3965 - val_loss: 1.4805 - val_accuracy: 0.4789\n",
      "Epoch 141/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5002 - accuracy: 0.4246 - val_loss: 1.4595 - val_accuracy: 0.4930\n",
      "Epoch 142/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4763 - accuracy: 0.4281 - val_loss: 1.4667 - val_accuracy: 0.4930\n",
      "Epoch 143/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4894 - accuracy: 0.4211 - val_loss: 1.4642 - val_accuracy: 0.4930\n",
      "Epoch 144/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5062 - accuracy: 0.4175 - val_loss: 1.4627 - val_accuracy: 0.4930\n",
      "Epoch 145/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4867 - accuracy: 0.4211 - val_loss: 1.4568 - val_accuracy: 0.4366\n",
      "Epoch 146/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5219 - accuracy: 0.3965 - val_loss: 1.4594 - val_accuracy: 0.4930\n",
      "Epoch 147/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5231 - accuracy: 0.4035 - val_loss: 1.4636 - val_accuracy: 0.4930\n",
      "Epoch 148/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4752 - accuracy: 0.4421 - val_loss: 1.4445 - val_accuracy: 0.4507\n",
      "Epoch 149/170\n",
      "285/285 [==============================] - 0s 120us/step - loss: 1.5161 - accuracy: 0.4175 - val_loss: 1.4650 - val_accuracy: 0.4789\n",
      "Epoch 150/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4989 - accuracy: 0.4211 - val_loss: 1.4658 - val_accuracy: 0.4789\n",
      "Epoch 151/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.4701 - accuracy: 0.4316 - val_loss: 1.4274 - val_accuracy: 0.4507\n",
      "Epoch 152/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4941 - accuracy: 0.4175 - val_loss: 1.4480 - val_accuracy: 0.4930\n",
      "Epoch 153/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5280 - accuracy: 0.4140 - val_loss: 1.4712 - val_accuracy: 0.4789\n",
      "Epoch 154/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5003 - accuracy: 0.4070 - val_loss: 1.4952 - val_accuracy: 0.4507\n",
      "Epoch 155/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5181 - accuracy: 0.3860 - val_loss: 1.4878 - val_accuracy: 0.4085\n",
      "Epoch 156/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5404 - accuracy: 0.3649 - val_loss: 1.5017 - val_accuracy: 0.4366\n",
      "Epoch 157/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5302 - accuracy: 0.3895 - val_loss: 1.4919 - val_accuracy: 0.4366\n",
      "Epoch 158/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5584 - accuracy: 0.3719 - val_loss: 1.4977 - val_accuracy: 0.4366\n",
      "Epoch 159/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.4932 - accuracy: 0.4140 - val_loss: 1.4834 - val_accuracy: 0.4085\n",
      "Epoch 160/170\n",
      "285/285 [==============================] - 0s 117us/step - loss: 1.5441 - accuracy: 0.3754 - val_loss: 1.4959 - val_accuracy: 0.4366\n",
      "Epoch 161/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.4998 - accuracy: 0.3930 - val_loss: 1.4816 - val_accuracy: 0.4085\n",
      "Epoch 162/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5237 - accuracy: 0.3895 - val_loss: 1.4924 - val_accuracy: 0.4366\n",
      "Epoch 163/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5073 - accuracy: 0.3930 - val_loss: 1.4844 - val_accuracy: 0.4366\n",
      "Epoch 164/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5100 - accuracy: 0.3895 - val_loss: 1.4808 - val_accuracy: 0.4085\n",
      "Epoch 165/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.4904 - accuracy: 0.4000 - val_loss: 1.4868 - val_accuracy: 0.4366\n",
      "Epoch 166/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.5812 - accuracy: 0.3719 - val_loss: 1.4866 - val_accuracy: 0.4366\n",
      "Epoch 167/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.5370 - accuracy: 0.3860 - val_loss: 1.5240 - val_accuracy: 0.4366\n",
      "Epoch 168/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5152 - accuracy: 0.3930 - val_loss: 1.4944 - val_accuracy: 0.4366\n",
      "Epoch 169/170\n",
      "285/285 [==============================] - 0s 116us/step - loss: 1.4739 - accuracy: 0.4000 - val_loss: 1.4734 - val_accuracy: 0.4225\n",
      "Epoch 170/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5408 - accuracy: 0.3789 - val_loss: 1.5044 - val_accuracy: 0.4366\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 285 samples, validate on 71 samples\n",
      "Epoch 1/170\n",
      "285/285 [==============================] - 0s 992us/step - loss: 130.4388 - accuracy: 0.0912 - val_loss: 9.9863 - val_accuracy: 0.0845\n",
      "Epoch 2/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 93.1982 - accuracy: 0.1298 - val_loss: 6.7669 - val_accuracy: 0.0704\n",
      "Epoch 3/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 44.9083 - accuracy: 0.1684 - val_loss: 4.5532 - val_accuracy: 0.2254\n",
      "Epoch 4/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 63.5000 - accuracy: 0.2000 - val_loss: 3.6406 - val_accuracy: 0.1831\n",
      "Epoch 5/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 23.8428 - accuracy: 0.2035 - val_loss: 2.8180 - val_accuracy: 0.0986\n",
      "Epoch 6/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 34.0830 - accuracy: 0.1719 - val_loss: 2.2202 - val_accuracy: 0.1972\n",
      "Epoch 7/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 10.5886 - accuracy: 0.2351 - val_loss: 2.0324 - val_accuracy: 0.2113\n",
      "Epoch 8/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 11.1701 - accuracy: 0.2246 - val_loss: 1.9973 - val_accuracy: 0.1831\n",
      "Epoch 9/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 6.4528 - accuracy: 0.2667 - val_loss: 1.9330 - val_accuracy: 0.2676\n",
      "Epoch 10/170\n",
      "285/285 [==============================] - 0s 102us/step - loss: 8.5830 - accuracy: 0.2456 - val_loss: 1.8906 - val_accuracy: 0.2394\n",
      "Epoch 11/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 1.8589 - accuracy: 0.2561 - val_loss: 1.8388 - val_accuracy: 0.3521\n",
      "Epoch 12/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 21.1880 - accuracy: 0.2807 - val_loss: 1.8370 - val_accuracy: 0.2958\n",
      "Epoch 13/170\n",
      "285/285 [==============================] - 0s 102us/step - loss: 8.4867 - accuracy: 0.2561 - val_loss: 1.8067 - val_accuracy: 0.2254\n",
      "Epoch 14/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 8.7034 - accuracy: 0.2737 - val_loss: 1.7995 - val_accuracy: 0.2535\n",
      "Epoch 15/170\n",
      "285/285 [==============================] - 0s 100us/step - loss: 3.7382 - accuracy: 0.2877 - val_loss: 1.8034 - val_accuracy: 0.2254\n",
      "Epoch 16/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 13.4480 - accuracy: 0.2316 - val_loss: 1.7900 - val_accuracy: 0.1972\n",
      "Epoch 17/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 4.8836 - accuracy: 0.2737 - val_loss: 1.7723 - val_accuracy: 0.2113\n",
      "Epoch 18/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 2.2687 - accuracy: 0.2877 - val_loss: 1.7549 - val_accuracy: 0.2113\n",
      "Epoch 19/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 6.7018 - accuracy: 0.2526 - val_loss: 1.7373 - val_accuracy: 0.2676\n",
      "Epoch 20/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.8056 - accuracy: 0.2947 - val_loss: 1.7292 - val_accuracy: 0.2958\n",
      "Epoch 21/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.7925 - accuracy: 0.2737 - val_loss: 1.7238 - val_accuracy: 0.2958\n",
      "Epoch 22/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.7985 - accuracy: 0.2842 - val_loss: 1.7010 - val_accuracy: 0.2817\n",
      "Epoch 23/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.9001 - accuracy: 0.2737 - val_loss: 1.7008 - val_accuracy: 0.2676\n",
      "Epoch 24/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 17.7953 - accuracy: 0.2667 - val_loss: 1.7079 - val_accuracy: 0.2676\n",
      "Epoch 25/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 3.1917 - accuracy: 0.2772 - val_loss: 1.6914 - val_accuracy: 0.2817\n",
      "Epoch 26/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 4.4403 - accuracy: 0.2807 - val_loss: 1.6819 - val_accuracy: 0.2958\n",
      "Epoch 27/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 2.1700 - accuracy: 0.2702 - val_loss: 1.6905 - val_accuracy: 0.3239\n",
      "Epoch 28/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 3.8767 - accuracy: 0.2842 - val_loss: 1.6958 - val_accuracy: 0.3099\n",
      "Epoch 29/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 12.1178 - accuracy: 0.2667 - val_loss: 1.6924 - val_accuracy: 0.2817\n",
      "Epoch 30/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.7256 - accuracy: 0.2912 - val_loss: 1.6892 - val_accuracy: 0.2817\n",
      "Epoch 31/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.6943 - accuracy: 0.2737 - val_loss: 1.6817 - val_accuracy: 0.2817\n",
      "Epoch 32/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 2.7547 - accuracy: 0.2596 - val_loss: 1.6860 - val_accuracy: 0.2958\n",
      "Epoch 33/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6926 - accuracy: 0.2842 - val_loss: 1.6894 - val_accuracy: 0.3099\n",
      "Epoch 34/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.7142 - accuracy: 0.3088 - val_loss: 1.6876 - val_accuracy: 0.3099\n",
      "Epoch 35/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 2.4425 - accuracy: 0.2772 - val_loss: 1.6783 - val_accuracy: 0.3380\n",
      "Epoch 36/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.7212 - accuracy: 0.2912 - val_loss: 1.6732 - val_accuracy: 0.3380\n",
      "Epoch 37/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6811 - accuracy: 0.2912 - val_loss: 1.6632 - val_accuracy: 0.3380\n",
      "Epoch 38/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.7871 - accuracy: 0.2947 - val_loss: 1.6602 - val_accuracy: 0.3380\n",
      "Epoch 39/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.7221 - accuracy: 0.2807 - val_loss: 1.6604 - val_accuracy: 0.3380\n",
      "Epoch 40/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 2.3300 - accuracy: 0.2877 - val_loss: 1.6499 - val_accuracy: 0.3380\n",
      "Epoch 41/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7601 - accuracy: 0.2877 - val_loss: 1.6320 - val_accuracy: 0.2958\n",
      "Epoch 42/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.7409 - accuracy: 0.2877 - val_loss: 1.6285 - val_accuracy: 0.3099\n",
      "Epoch 43/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7176 - accuracy: 0.2807 - val_loss: 1.6342 - val_accuracy: 0.3099\n",
      "Epoch 44/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.8190 - accuracy: 0.3123 - val_loss: 1.6096 - val_accuracy: 0.3380\n",
      "Epoch 45/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 8.7199 - accuracy: 0.2807 - val_loss: 1.5669 - val_accuracy: 0.3380\n",
      "Epoch 46/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 2.3437 - accuracy: 0.2807 - val_loss: 1.5731 - val_accuracy: 0.3380\n",
      "Epoch 47/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7060 - accuracy: 0.2807 - val_loss: 1.5759 - val_accuracy: 0.3380\n",
      "Epoch 48/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.6816 - accuracy: 0.2632 - val_loss: 1.5984 - val_accuracy: 0.3380\n",
      "Epoch 49/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 2.8024 - accuracy: 0.2772 - val_loss: 1.6234 - val_accuracy: 0.3380\n",
      "Epoch 50/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 2.2073 - accuracy: 0.2912 - val_loss: 1.5983 - val_accuracy: 0.3380\n",
      "Epoch 51/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.7695 - accuracy: 0.2912 - val_loss: 1.5989 - val_accuracy: 0.3380\n",
      "Epoch 52/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.6456 - accuracy: 0.2912 - val_loss: 1.6109 - val_accuracy: 0.3380\n",
      "Epoch 53/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6539 - accuracy: 0.2982 - val_loss: 1.6010 - val_accuracy: 0.3380\n",
      "Epoch 54/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6533 - accuracy: 0.2947 - val_loss: 1.5794 - val_accuracy: 0.3380\n",
      "Epoch 55/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 2.1957 - accuracy: 0.2877 - val_loss: 1.5774 - val_accuracy: 0.3380\n",
      "Epoch 56/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.8410 - accuracy: 0.2737 - val_loss: 1.5920 - val_accuracy: 0.3380\n",
      "Epoch 57/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6353 - accuracy: 0.3018 - val_loss: 1.6261 - val_accuracy: 0.3099\n",
      "Epoch 58/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6385 - accuracy: 0.3018 - val_loss: 1.6077 - val_accuracy: 0.3380\n",
      "Epoch 59/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6592 - accuracy: 0.2877 - val_loss: 1.5715 - val_accuracy: 0.3380\n",
      "Epoch 60/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7805 - accuracy: 0.2842 - val_loss: 1.5640 - val_accuracy: 0.3380\n",
      "Epoch 61/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 2.4198 - accuracy: 0.2807 - val_loss: 1.5710 - val_accuracy: 0.3380\n",
      "Epoch 62/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 7.3122 - accuracy: 0.2842 - val_loss: 1.5536 - val_accuracy: 0.3380\n",
      "Epoch 63/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.6275 - accuracy: 0.2877 - val_loss: 1.5573 - val_accuracy: 0.3239\n",
      "Epoch 64/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 3.1817 - accuracy: 0.2702 - val_loss: 1.5598 - val_accuracy: 0.3239\n",
      "Epoch 65/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 2.3712 - accuracy: 0.2947 - val_loss: 1.5445 - val_accuracy: 0.3380\n",
      "Epoch 66/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.8617 - accuracy: 0.2877 - val_loss: 1.5579 - val_accuracy: 0.3380\n",
      "Epoch 67/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.9369 - accuracy: 0.2737 - val_loss: 1.5554 - val_accuracy: 0.3380\n",
      "Epoch 68/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6851 - accuracy: 0.2772 - val_loss: 1.5444 - val_accuracy: 0.3239\n",
      "Epoch 69/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 2.0859 - accuracy: 0.3298 - val_loss: 1.5458 - val_accuracy: 0.3239\n",
      "Epoch 70/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6374 - accuracy: 0.2772 - val_loss: 1.5487 - val_accuracy: 0.3239\n",
      "Epoch 71/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 1.6187 - accuracy: 0.3158 - val_loss: 1.5546 - val_accuracy: 0.3239\n",
      "Epoch 72/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6258 - accuracy: 0.3088 - val_loss: 1.5530 - val_accuracy: 0.3239\n",
      "Epoch 73/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 2.1786 - accuracy: 0.3158 - val_loss: 1.5510 - val_accuracy: 0.3239\n",
      "Epoch 74/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.9524 - accuracy: 0.2912 - val_loss: 1.5508 - val_accuracy: 0.3239\n",
      "Epoch 75/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.6573 - accuracy: 0.2877 - val_loss: 1.5616 - val_accuracy: 0.3239\n",
      "Epoch 76/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 3.1884 - accuracy: 0.3088 - val_loss: 1.5574 - val_accuracy: 0.3239\n",
      "Epoch 77/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.7020 - accuracy: 0.2947 - val_loss: 1.5695 - val_accuracy: 0.3099\n",
      "Epoch 78/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.7939 - accuracy: 0.2982 - val_loss: 1.5694 - val_accuracy: 0.3239\n",
      "Epoch 79/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.6380 - accuracy: 0.3298 - val_loss: 1.5713 - val_accuracy: 0.3099\n",
      "Epoch 80/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7190 - accuracy: 0.3053 - val_loss: 1.5575 - val_accuracy: 0.3239\n",
      "Epoch 81/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.8349 - accuracy: 0.3053 - val_loss: 1.5531 - val_accuracy: 0.3239\n",
      "Epoch 82/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6195 - accuracy: 0.3018 - val_loss: 1.5596 - val_accuracy: 0.3380\n",
      "Epoch 83/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 1.6206 - accuracy: 0.2947 - val_loss: 1.5737 - val_accuracy: 0.3239\n",
      "Epoch 84/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.6046 - accuracy: 0.3263 - val_loss: 1.5515 - val_accuracy: 0.3099\n",
      "Epoch 85/170\n",
      "285/285 [==============================] - 0s 104us/step - loss: 1.5891 - accuracy: 0.3053 - val_loss: 1.5457 - val_accuracy: 0.3099\n",
      "Epoch 86/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.6147 - accuracy: 0.3053 - val_loss: 1.5440 - val_accuracy: 0.3239\n",
      "Epoch 87/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5775 - accuracy: 0.3088 - val_loss: 1.5314 - val_accuracy: 0.3239\n",
      "Epoch 88/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.8509 - accuracy: 0.2947 - val_loss: 1.5424 - val_accuracy: 0.3239\n",
      "Epoch 89/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.6873 - accuracy: 0.3439 - val_loss: 1.5497 - val_accuracy: 0.3239\n",
      "Epoch 90/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7518 - accuracy: 0.3333 - val_loss: 1.5492 - val_accuracy: 0.3239\n",
      "Epoch 91/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.6792 - accuracy: 0.3579 - val_loss: 1.5350 - val_accuracy: 0.4648\n",
      "Epoch 92/170\n",
      "285/285 [==============================] - 0s 100us/step - loss: 2.1653 - accuracy: 0.4070 - val_loss: 1.5347 - val_accuracy: 0.5070\n",
      "Epoch 93/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 1.6154 - accuracy: 0.4070 - val_loss: 1.5242 - val_accuracy: 0.5211\n",
      "Epoch 94/170\n",
      "285/285 [==============================] - 0s 102us/step - loss: 1.5857 - accuracy: 0.4070 - val_loss: 1.5449 - val_accuracy: 0.5352\n",
      "Epoch 95/170\n",
      "285/285 [==============================] - 0s 129us/step - loss: 1.6954 - accuracy: 0.4070 - val_loss: 1.5477 - val_accuracy: 0.5070\n",
      "Epoch 96/170\n",
      "285/285 [==============================] - 0s 126us/step - loss: 1.5786 - accuracy: 0.4140 - val_loss: 1.5354 - val_accuracy: 0.5352\n",
      "Epoch 97/170\n",
      "285/285 [==============================] - 0s 128us/step - loss: 1.5874 - accuracy: 0.4281 - val_loss: 1.5559 - val_accuracy: 0.4789\n",
      "Epoch 98/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 1.6403 - accuracy: 0.4035 - val_loss: 1.5495 - val_accuracy: 0.5070\n",
      "Epoch 99/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 1.6189 - accuracy: 0.3684 - val_loss: 1.5322 - val_accuracy: 0.5070\n",
      "Epoch 100/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.9160 - accuracy: 0.4386 - val_loss: 1.5350 - val_accuracy: 0.5070\n",
      "Epoch 101/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6088 - accuracy: 0.3509 - val_loss: 1.5350 - val_accuracy: 0.5070\n",
      "Epoch 102/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6144 - accuracy: 0.4175 - val_loss: 1.5267 - val_accuracy: 0.5070\n",
      "Epoch 103/170\n",
      "285/285 [==============================] - 0s 102us/step - loss: 1.5807 - accuracy: 0.4281 - val_loss: 1.5172 - val_accuracy: 0.5352\n",
      "Epoch 104/170\n",
      "285/285 [==============================] - 0s 100us/step - loss: 1.5500 - accuracy: 0.4281 - val_loss: 1.5267 - val_accuracy: 0.5211\n",
      "Epoch 105/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5665 - accuracy: 0.4281 - val_loss: 1.5214 - val_accuracy: 0.5211\n",
      "Epoch 106/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6511 - accuracy: 0.4351 - val_loss: 1.5097 - val_accuracy: 0.5352\n",
      "Epoch 107/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.5589 - accuracy: 0.4702 - val_loss: 1.5238 - val_accuracy: 0.5493\n",
      "Epoch 108/170\n",
      "285/285 [==============================] - 0s 101us/step - loss: 1.5628 - accuracy: 0.4281 - val_loss: 1.5166 - val_accuracy: 0.5070\n",
      "Epoch 109/170\n",
      "285/285 [==============================] - 0s 102us/step - loss: 1.5865 - accuracy: 0.4000 - val_loss: 1.5178 - val_accuracy: 0.5493\n",
      "Epoch 110/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6039 - accuracy: 0.4316 - val_loss: 1.5158 - val_accuracy: 0.5352\n",
      "Epoch 111/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.6181 - accuracy: 0.4140 - val_loss: 1.5153 - val_accuracy: 0.5070\n",
      "Epoch 112/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 2.8526 - accuracy: 0.4386 - val_loss: 1.5117 - val_accuracy: 0.5493\n",
      "Epoch 113/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5435 - accuracy: 0.4281 - val_loss: 1.5094 - val_accuracy: 0.5352\n",
      "Epoch 114/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5603 - accuracy: 0.4561 - val_loss: 1.5249 - val_accuracy: 0.5352\n",
      "Epoch 115/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5450 - accuracy: 0.4316 - val_loss: 1.5297 - val_accuracy: 0.5352\n",
      "Epoch 116/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.5363 - accuracy: 0.4351 - val_loss: 1.4980 - val_accuracy: 0.5352\n",
      "Epoch 117/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 5.1755 - accuracy: 0.4316 - val_loss: 1.5128 - val_accuracy: 0.5493\n",
      "Epoch 118/170\n",
      "285/285 [==============================] - 0s 121us/step - loss: 2.5268 - accuracy: 0.4246 - val_loss: 1.5461 - val_accuracy: 0.5211\n",
      "Epoch 119/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7356 - accuracy: 0.3965 - val_loss: 1.5222 - val_accuracy: 0.5211\n",
      "Epoch 120/170\n",
      "285/285 [==============================] - 0s 118us/step - loss: 1.7786 - accuracy: 0.4316 - val_loss: 1.5202 - val_accuracy: 0.5211\n",
      "Epoch 121/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7175 - accuracy: 0.4105 - val_loss: 1.5469 - val_accuracy: 0.5352\n",
      "Epoch 122/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.7260 - accuracy: 0.4000 - val_loss: 1.5318 - val_accuracy: 0.5211\n",
      "Epoch 123/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 2.2355 - accuracy: 0.4456 - val_loss: 1.5127 - val_accuracy: 0.5211\n",
      "Epoch 124/170\n",
      "285/285 [==============================] - 0s 113us/step - loss: 1.5154 - accuracy: 0.4140 - val_loss: 1.5205 - val_accuracy: 0.5211\n",
      "Epoch 125/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5932 - accuracy: 0.4105 - val_loss: 1.5102 - val_accuracy: 0.5211\n",
      "Epoch 126/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 2.2094 - accuracy: 0.4070 - val_loss: 1.5295 - val_accuracy: 0.5352\n",
      "Epoch 127/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.6857 - accuracy: 0.4246 - val_loss: 1.5245 - val_accuracy: 0.5352\n",
      "Epoch 128/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.8227 - accuracy: 0.4596 - val_loss: 1.4825 - val_accuracy: 0.5352\n",
      "Epoch 129/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.5361 - accuracy: 0.4386 - val_loss: 1.4950 - val_accuracy: 0.5352\n",
      "Epoch 130/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5307 - accuracy: 0.4456 - val_loss: 1.4876 - val_accuracy: 0.5493\n",
      "Epoch 131/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.7870 - accuracy: 0.4175 - val_loss: 1.4830 - val_accuracy: 0.5493\n",
      "Epoch 132/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5484 - accuracy: 0.4281 - val_loss: 1.4903 - val_accuracy: 0.5493\n",
      "Epoch 133/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5526 - accuracy: 0.4000 - val_loss: 1.4883 - val_accuracy: 0.5493\n",
      "Epoch 134/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.7518 - accuracy: 0.4035 - val_loss: 1.4902 - val_accuracy: 0.5493\n",
      "Epoch 135/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.5583 - accuracy: 0.3965 - val_loss: 1.5118 - val_accuracy: 0.5211\n",
      "Epoch 136/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5431 - accuracy: 0.4211 - val_loss: 1.5049 - val_accuracy: 0.5352\n",
      "Epoch 137/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5366 - accuracy: 0.4386 - val_loss: 1.4988 - val_accuracy: 0.5352\n",
      "Epoch 138/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.7203 - accuracy: 0.4246 - val_loss: 1.4809 - val_accuracy: 0.5352\n",
      "Epoch 139/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 2.3627 - accuracy: 0.4281 - val_loss: 1.5022 - val_accuracy: 0.5352\n",
      "Epoch 140/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.4957 - accuracy: 0.4421 - val_loss: 1.4523 - val_accuracy: 0.5634\n",
      "Epoch 141/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5593 - accuracy: 0.4035 - val_loss: 1.4924 - val_accuracy: 0.5352\n",
      "Epoch 142/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.7128 - accuracy: 0.4351 - val_loss: 1.4979 - val_accuracy: 0.5493\n",
      "Epoch 143/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.7301 - accuracy: 0.4526 - val_loss: 1.4730 - val_accuracy: 0.5493\n",
      "Epoch 144/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5598 - accuracy: 0.4246 - val_loss: 1.4976 - val_accuracy: 0.5493\n",
      "Epoch 145/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5220 - accuracy: 0.4175 - val_loss: 1.4687 - val_accuracy: 0.5493\n",
      "Epoch 146/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.5436 - accuracy: 0.4281 - val_loss: 1.4894 - val_accuracy: 0.5493\n",
      "Epoch 147/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.9359 - accuracy: 0.4035 - val_loss: 1.4987 - val_accuracy: 0.5352\n",
      "Epoch 148/170\n",
      "285/285 [==============================] - 0s 111us/step - loss: 1.5364 - accuracy: 0.4281 - val_loss: 1.4739 - val_accuracy: 0.5634\n",
      "Epoch 149/170\n",
      "285/285 [==============================] - 0s 115us/step - loss: 1.5555 - accuracy: 0.3860 - val_loss: 1.4893 - val_accuracy: 0.5493\n",
      "Epoch 150/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5983 - accuracy: 0.4421 - val_loss: 1.4851 - val_accuracy: 0.5493\n",
      "Epoch 151/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.6267 - accuracy: 0.4035 - val_loss: 1.4576 - val_accuracy: 0.5634\n",
      "Epoch 152/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5277 - accuracy: 0.4246 - val_loss: 1.4666 - val_accuracy: 0.5493\n",
      "Epoch 153/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5304 - accuracy: 0.4246 - val_loss: 1.4846 - val_accuracy: 0.5352\n",
      "Epoch 154/170\n",
      "285/285 [==============================] - 0s 112us/step - loss: 1.5476 - accuracy: 0.4772 - val_loss: 1.4824 - val_accuracy: 0.5352\n",
      "Epoch 155/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.5242 - accuracy: 0.4140 - val_loss: 1.4729 - val_accuracy: 0.5352\n",
      "Epoch 156/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 1.5288 - accuracy: 0.4351 - val_loss: 1.4822 - val_accuracy: 0.5352\n",
      "Epoch 157/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.8523 - accuracy: 0.4281 - val_loss: 1.4623 - val_accuracy: 0.5493\n",
      "Epoch 158/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4878 - accuracy: 0.4702 - val_loss: 1.4663 - val_accuracy: 0.5493\n",
      "Epoch 159/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.5183 - accuracy: 0.4281 - val_loss: 1.4660 - val_accuracy: 0.5352\n",
      "Epoch 160/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.4794 - accuracy: 0.4667 - val_loss: 1.4803 - val_accuracy: 0.5352\n",
      "Epoch 161/170\n",
      "285/285 [==============================] - 0s 106us/step - loss: 1.4984 - accuracy: 0.4667 - val_loss: 1.4487 - val_accuracy: 0.5493\n",
      "Epoch 162/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.5229 - accuracy: 0.4316 - val_loss: 1.4644 - val_accuracy: 0.5352\n",
      "Epoch 163/170\n",
      "285/285 [==============================] - 0s 109us/step - loss: 1.4899 - accuracy: 0.4807 - val_loss: 1.4498 - val_accuracy: 0.5493\n",
      "Epoch 164/170\n",
      "285/285 [==============================] - 0s 105us/step - loss: 1.5266 - accuracy: 0.4702 - val_loss: 1.4461 - val_accuracy: 0.5493\n",
      "Epoch 165/170\n",
      "285/285 [==============================] - 0s 103us/step - loss: 1.5682 - accuracy: 0.4491 - val_loss: 1.4394 - val_accuracy: 0.5493\n",
      "Epoch 166/170\n",
      "285/285 [==============================] - 0s 108us/step - loss: 1.4920 - accuracy: 0.4491 - val_loss: 1.4714 - val_accuracy: 0.5352\n",
      "Epoch 167/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.4912 - accuracy: 0.4842 - val_loss: 1.4454 - val_accuracy: 0.5493\n",
      "Epoch 168/170\n",
      "285/285 [==============================] - 0s 114us/step - loss: 1.5356 - accuracy: 0.4561 - val_loss: 1.4505 - val_accuracy: 0.5493\n",
      "Epoch 169/170\n",
      "285/285 [==============================] - 0s 107us/step - loss: 1.5168 - accuracy: 0.4316 - val_loss: 1.4499 - val_accuracy: 0.5493\n",
      "Epoch 170/170\n",
      "285/285 [==============================] - 0s 110us/step - loss: 1.5002 - accuracy: 0.4596 - val_loss: 1.4595 - val_accuracy: 0.5352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main iteration is: 164\n"
     ]
    }
   ],
   "source": [
    "main_iterr = model_train(x_train, y_train_enc, 5, 170, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4akZMCSWgXMg",
    "outputId": "a406efc6-b31c-4702-fcfd-ddadb9f3d251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/164\n",
      "356/356 [==============================] - 0s 657us/step - loss: 25.0378 - accuracy: 0.2416\n",
      "Epoch 2/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 2.8894 - accuracy: 0.2275\n",
      "Epoch 3/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 3.7910 - accuracy: 0.1573\n",
      "Epoch 4/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 5.1239 - accuracy: 0.2444\n",
      "Epoch 5/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 21.0320 - accuracy: 0.2809\n",
      "Epoch 6/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 4.4563 - accuracy: 0.3034\n",
      "Epoch 7/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 3.1295 - accuracy: 0.3258\n",
      "Epoch 8/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 9.2890 - accuracy: 0.3202\n",
      "Epoch 9/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 11.6811 - accuracy: 0.3258\n",
      "Epoch 10/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 7.7284 - accuracy: 0.3174\n",
      "Epoch 11/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 8.6633 - accuracy: 0.2921\n",
      "Epoch 12/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 4.5626 - accuracy: 0.3062\n",
      "Epoch 13/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 8.1027 - accuracy: 0.2921\n",
      "Epoch 14/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 2.2749 - accuracy: 0.3202\n",
      "Epoch 15/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 2.6679 - accuracy: 0.3146\n",
      "Epoch 16/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 6.0351 - accuracy: 0.3118\n",
      "Epoch 17/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 5.6647 - accuracy: 0.2893\n",
      "Epoch 18/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.7173 - accuracy: 0.3118\n",
      "Epoch 19/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 4.1213 - accuracy: 0.3539\n",
      "Epoch 20/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 3.3352 - accuracy: 0.2921\n",
      "Epoch 21/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 2.5111 - accuracy: 0.3090\n",
      "Epoch 22/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 2.1457 - accuracy: 0.3202\n",
      "Epoch 23/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.9716 - accuracy: 0.2978\n",
      "Epoch 24/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 2.0300 - accuracy: 0.3287\n",
      "Epoch 25/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 5.5669 - accuracy: 0.3202\n",
      "Epoch 26/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 3.5006 - accuracy: 0.3427\n",
      "Epoch 27/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 2.1448 - accuracy: 0.3399\n",
      "Epoch 28/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 3.8228 - accuracy: 0.3427\n",
      "Epoch 29/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 3.4958 - accuracy: 0.3371\n",
      "Epoch 30/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 2.2765 - accuracy: 0.3118\n",
      "Epoch 31/164\n",
      "356/356 [==============================] - 0s 84us/step - loss: 3.1101 - accuracy: 0.3146\n",
      "Epoch 32/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.8102 - accuracy: 0.3287\n",
      "Epoch 33/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.6494 - accuracy: 0.3399\n",
      "Epoch 34/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.6486 - accuracy: 0.3399\n",
      "Epoch 35/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.6336 - accuracy: 0.3118\n",
      "Epoch 36/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 1.6326 - accuracy: 0.3118\n",
      "Epoch 37/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.6277 - accuracy: 0.3258\n",
      "Epoch 38/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.6299 - accuracy: 0.3230\n",
      "Epoch 39/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.6208 - accuracy: 0.2949\n",
      "Epoch 40/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.6414 - accuracy: 0.3062\n",
      "Epoch 41/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 1.6101 - accuracy: 0.3146\n",
      "Epoch 42/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.6226 - accuracy: 0.2978\n",
      "Epoch 43/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.6084 - accuracy: 0.3006\n",
      "Epoch 44/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.6329 - accuracy: 0.3174\n",
      "Epoch 45/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.5999 - accuracy: 0.3371\n",
      "Epoch 46/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.6158 - accuracy: 0.2809\n",
      "Epoch 47/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.5991 - accuracy: 0.3371\n",
      "Epoch 48/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.6040 - accuracy: 0.3118\n",
      "Epoch 49/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.5943 - accuracy: 0.3596\n",
      "Epoch 50/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.6045 - accuracy: 0.3287\n",
      "Epoch 51/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 1.5727 - accuracy: 0.3230\n",
      "Epoch 52/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.5467 - accuracy: 0.3258\n",
      "Epoch 53/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5706 - accuracy: 0.3034\n",
      "Epoch 54/164\n",
      "356/356 [==============================] - 0s 96us/step - loss: 1.5573 - accuracy: 0.3427\n",
      "Epoch 55/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5395 - accuracy: 0.3343\n",
      "Epoch 56/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.5613 - accuracy: 0.3596\n",
      "Epoch 57/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.5740 - accuracy: 0.3258\n",
      "Epoch 58/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.5447 - accuracy: 0.3455\n",
      "Epoch 59/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.5600 - accuracy: 0.3202\n",
      "Epoch 60/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.5562 - accuracy: 0.3511\n",
      "Epoch 61/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.5488 - accuracy: 0.4494\n",
      "Epoch 62/164\n",
      "356/356 [==============================] - 0s 96us/step - loss: 1.5481 - accuracy: 0.4410\n",
      "Epoch 63/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.5262 - accuracy: 0.4213\n",
      "Epoch 64/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.5578 - accuracy: 0.4354\n",
      "Epoch 65/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5457 - accuracy: 0.4326\n",
      "Epoch 66/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5422 - accuracy: 0.4326\n",
      "Epoch 67/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.8201 - accuracy: 0.4691\n",
      "Epoch 68/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.6060 - accuracy: 0.3258\n",
      "Epoch 69/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.6064 - accuracy: 0.3090\n",
      "Epoch 70/164\n",
      "356/356 [==============================] - 0s 96us/step - loss: 1.6193 - accuracy: 0.3258\n",
      "Epoch 71/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.6069 - accuracy: 0.3596\n",
      "Epoch 72/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.6078 - accuracy: 0.3792\n",
      "Epoch 73/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.5801 - accuracy: 0.4101\n",
      "Epoch 74/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.5723 - accuracy: 0.4157\n",
      "Epoch 75/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.5729 - accuracy: 0.4185\n",
      "Epoch 76/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.7480 - accuracy: 0.4242\n",
      "Epoch 77/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5833 - accuracy: 0.4073\n",
      "Epoch 78/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5894 - accuracy: 0.3708\n",
      "Epoch 79/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.5771 - accuracy: 0.3989\n",
      "Epoch 80/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.5602 - accuracy: 0.4410\n",
      "Epoch 81/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.5861 - accuracy: 0.4073\n",
      "Epoch 82/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5725 - accuracy: 0.4045\n",
      "Epoch 83/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5505 - accuracy: 0.4438\n",
      "Epoch 84/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.5480 - accuracy: 0.4466\n",
      "Epoch 85/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.5440 - accuracy: 0.4017\n",
      "Epoch 86/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.5441 - accuracy: 0.4185\n",
      "Epoch 87/164\n",
      "356/356 [==============================] - 0s 96us/step - loss: 1.5465 - accuracy: 0.4522\n",
      "Epoch 88/164\n",
      "356/356 [==============================] - 0s 96us/step - loss: 1.5444 - accuracy: 0.4185\n",
      "Epoch 89/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5453 - accuracy: 0.4522\n",
      "Epoch 90/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.5488 - accuracy: 0.4466\n",
      "Epoch 91/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5573 - accuracy: 0.4101\n",
      "Epoch 92/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.5413 - accuracy: 0.4635\n",
      "Epoch 93/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.5548 - accuracy: 0.4410\n",
      "Epoch 94/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5086 - accuracy: 0.4354\n",
      "Epoch 95/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.5293 - accuracy: 0.4522\n",
      "Epoch 96/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.5586 - accuracy: 0.4382\n",
      "Epoch 97/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5243 - accuracy: 0.4438\n",
      "Epoch 98/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.5099 - accuracy: 0.4551\n",
      "Epoch 99/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5233 - accuracy: 0.4185\n",
      "Epoch 100/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5068 - accuracy: 0.4663\n",
      "Epoch 101/164\n",
      "356/356 [==============================] - 0s 96us/step - loss: 1.5110 - accuracy: 0.4691\n",
      "Epoch 102/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5083 - accuracy: 0.4607\n",
      "Epoch 103/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4842 - accuracy: 0.4775\n",
      "Epoch 104/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.4878 - accuracy: 0.4831\n",
      "Epoch 105/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4832 - accuracy: 0.4831\n",
      "Epoch 106/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.4799 - accuracy: 0.4916\n",
      "Epoch 107/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5053 - accuracy: 0.4579\n",
      "Epoch 108/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.4692 - accuracy: 0.4972\n",
      "Epoch 109/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.5069 - accuracy: 0.4410\n",
      "Epoch 110/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.4681 - accuracy: 0.4803\n",
      "Epoch 111/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.5170 - accuracy: 0.4298\n",
      "Epoch 112/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.4700 - accuracy: 0.4803\n",
      "Epoch 113/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4950 - accuracy: 0.4775\n",
      "Epoch 114/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4703 - accuracy: 0.4972\n",
      "Epoch 115/164\n",
      "356/356 [==============================] - 0s 95us/step - loss: 1.4572 - accuracy: 0.4860\n",
      "Epoch 116/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.4665 - accuracy: 0.4747\n",
      "Epoch 117/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4845 - accuracy: 0.4803\n",
      "Epoch 118/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.4894 - accuracy: 0.4831\n",
      "Epoch 119/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4650 - accuracy: 0.5000\n",
      "Epoch 120/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4598 - accuracy: 0.4747\n",
      "Epoch 121/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4640 - accuracy: 0.4916\n",
      "Epoch 122/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4503 - accuracy: 0.4916\n",
      "Epoch 123/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4784 - accuracy: 0.4888\n",
      "Epoch 124/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.4956 - accuracy: 0.4522\n",
      "Epoch 125/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.4839 - accuracy: 0.4607\n",
      "Epoch 126/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.5004 - accuracy: 0.4831\n",
      "Epoch 127/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.4891 - accuracy: 0.4438\n",
      "Epoch 128/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.5224 - accuracy: 0.4073\n",
      "Epoch 129/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.4676 - accuracy: 0.4944\n",
      "Epoch 130/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4651 - accuracy: 0.5084\n",
      "Epoch 131/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.4877 - accuracy: 0.4607\n",
      "Epoch 132/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4668 - accuracy: 0.4551\n",
      "Epoch 133/164\n",
      "356/356 [==============================] - 0s 94us/step - loss: 1.4567 - accuracy: 0.4635\n",
      "Epoch 134/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 1.4594 - accuracy: 0.4775\n",
      "Epoch 135/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4610 - accuracy: 0.4663\n",
      "Epoch 136/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4476 - accuracy: 0.4803\n",
      "Epoch 137/164\n",
      "356/356 [==============================] - 0s 84us/step - loss: 1.4677 - accuracy: 0.4579\n",
      "Epoch 138/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.4467 - accuracy: 0.4663\n",
      "Epoch 139/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4532 - accuracy: 0.4860\n",
      "Epoch 140/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.4638 - accuracy: 0.4944\n",
      "Epoch 141/164\n",
      "356/356 [==============================] - 0s 85us/step - loss: 1.4363 - accuracy: 0.4831\n",
      "Epoch 142/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.4618 - accuracy: 0.4747\n",
      "Epoch 143/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4838 - accuracy: 0.4831\n",
      "Epoch 144/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4437 - accuracy: 0.4747\n",
      "Epoch 145/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.4538 - accuracy: 0.4747\n",
      "Epoch 146/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4727 - accuracy: 0.4831\n",
      "Epoch 147/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.4790 - accuracy: 0.4551\n",
      "Epoch 148/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4307 - accuracy: 0.5084\n",
      "Epoch 149/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4711 - accuracy: 0.4747\n",
      "Epoch 150/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.4427 - accuracy: 0.4522\n",
      "Epoch 151/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.4357 - accuracy: 0.4747\n",
      "Epoch 152/164\n",
      "356/356 [==============================] - 0s 93us/step - loss: 1.4480 - accuracy: 0.4944\n",
      "Epoch 153/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4313 - accuracy: 0.4916\n",
      "Epoch 154/164\n",
      "356/356 [==============================] - 0s 90us/step - loss: 1.4764 - accuracy: 0.4607\n",
      "Epoch 155/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.4394 - accuracy: 0.4775\n",
      "Epoch 156/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.4629 - accuracy: 0.4691\n",
      "Epoch 157/164\n",
      "356/356 [==============================] - 0s 92us/step - loss: 1.4968 - accuracy: 0.4298\n",
      "Epoch 158/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4378 - accuracy: 0.4803\n",
      "Epoch 159/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4525 - accuracy: 0.4635\n",
      "Epoch 160/164\n",
      "356/356 [==============================] - 0s 89us/step - loss: 1.4213 - accuracy: 0.5000\n",
      "Epoch 161/164\n",
      "356/356 [==============================] - 0s 87us/step - loss: 1.4475 - accuracy: 0.4719\n",
      "Epoch 162/164\n",
      "356/356 [==============================] - 0s 86us/step - loss: 1.4530 - accuracy: 0.4607\n",
      "Epoch 163/164\n",
      "356/356 [==============================] - 0s 91us/step - loss: 1.4144 - accuracy: 0.4860\n",
      "Epoch 164/164\n",
      "356/356 [==============================] - 0s 88us/step - loss: 1.4639 - accuracy: 0.4522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffb40d42550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = create_model()\n",
    "new_model.fit(x_train, y_train_enc, epochs=main_iterr, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hK9409hAjjyb",
    "outputId": "a8efa8d4-201b-42ad-e92f-e55f31c76379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3406103507856304, 0.5786516666412354]\n"
     ]
    }
   ],
   "source": [
    "scores = new_model.evaluate(x_train, y_train_enc, verbose=0)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlj3GiVN8FHG"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/bitsf312-lab1/test.csv\",encoding=\"utf-8\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "2q6vx-io-jhM",
    "outputId": "93529947-be72-48ea-b727-5156967a8ccb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>35</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.951158</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.534513</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>39</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5.918632</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8.226405</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077213</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Quantities  Number of Insignificant Quantities    Size  \\\n",
       "ID                                                                      \n",
       "371                     2                                   0  Medium   \n",
       "372                     2                                   0  Medium   \n",
       "373                     3                                   1  Medium   \n",
       "374                     2                                   0  Medium   \n",
       "375                     2                                   0  Medium   \n",
       "\n",
       "     Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                       \n",
       "371                     35                         108   \n",
       "372                     16                          53   \n",
       "373                     39                         140   \n",
       "374                     17                          59   \n",
       "375                     18                          74   \n",
       "\n",
       "     Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                    \n",
       "371                             3                    3            0   \n",
       "372                             2                    2            2   \n",
       "373                             3                    3            2   \n",
       "374                             3                    3            2   \n",
       "375                             2                    2            2   \n",
       "\n",
       "     Second Index  Difficulty  Score  \n",
       "ID                                    \n",
       "371            10    3.951158   21.0  \n",
       "372             5    6.534513    5.0  \n",
       "373            18    5.918632    9.0  \n",
       "374             7    8.226405   58.0  \n",
       "375             6    5.077213  105.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "colab_type": "code",
    "id": "MOUGEwdr-lx1",
    "outputId": "962c9e60-92ca-47f1-dcf4-b140a4a58405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Quantities [2 3]\n",
      "Number of Insignificant Quantities [0 1]\n",
      "Size ['Medium' 'Big' 'Small']\n",
      "Total Number of Words [35 16 39 17 18 23 22 31 19 24 20 27 21 26 25 28 37 30 29 32 14 34]\n",
      "Total Number of Characters [108  53 140  59  74  84  77 109  64  95  81 111  70  83  58  82  73  69\n",
      "  75  80  98  97  85  71  62  87 101  55  67  78 121 100  79  51  60 119\n",
      "  94 125  72  91 103  36  65  66 106 107  61 104  88  76  68  93  86  92\n",
      "  96 110 139 105  99 124  90 117 102 132 115]\n",
      "Number of Special Characters [3 2 1 4 7]\n",
      "Number of Sentences [3 2 1 4 7]\n",
      "First Index [ 0  2  3  4  5 11  9 10  6  7 12 15]\n",
      "Second Index [10  5 18  7  6 13 11 14  8 16  9 15 20 12 17 19 21]\n",
      "Difficulty [3.95115847 6.53451347 5.91863208 8.22640547 5.07721278 6.39265636\n",
      " 5.73205455 0.3018889  7.49325924 3.47131815 5.00116157 5.94505973\n",
      " 9.04104537 2.3189681  0.77672096 6.03061442 6.74744815 1.2209892\n",
      " 1.67978236 0.77407546 8.68809086 7.63686118 6.29261948 6.22909031\n",
      " 8.50221857 9.98210197 8.70999719 1.2814208  3.34849302 6.30606139\n",
      " 5.65605513 3.37743144 6.758096   4.32832752 9.63018668 2.48434059\n",
      " 3.89603301 4.78259588 4.16329655 4.07943284 6.18685418 0.89456618\n",
      " 4.79563545 8.34824899 9.98930568 5.35010761 5.19474276 5.09726843\n",
      " 8.7898647  8.34331124 1.13543852 3.50402497 6.57329509 0.22095257\n",
      " 6.19277703 7.5216648  1.46386666 7.68404419 6.39412331 4.37229991\n",
      " 6.62898921 6.55700931 0.84763377 6.11087727 5.04663436 8.79212004\n",
      " 8.84042805 0.05521605 5.54340365 7.6326012  7.67718657 2.32832917\n",
      " 0.22637398 0.66194065 1.1925928  1.99671642 2.43852261 4.15278403\n",
      " 3.51812812 7.99256028 6.71888008 2.84809873 8.08083227 7.87035027\n",
      " 7.85670261 7.63726599 5.02269734 7.78637196 3.49105925 3.18559751\n",
      " 9.00246717 5.64197998 4.82036405 0.9630087  2.94912904 9.14657582\n",
      " 5.52287006 1.71277892 0.41264768 8.42290259 6.65234506 0.76472142\n",
      " 1.13784408 0.48406493 4.37551273 8.97442316 3.4176356  1.93055692\n",
      " 8.44220714 4.72537896 0.99539119 6.59789739 8.5631669  8.07853\n",
      " 1.36339475 7.58893935 5.49111419 3.02941195 8.99597104 6.41507488\n",
      " 9.3464215  9.45562761 7.32725044 7.0879067  5.99335146 4.23237465\n",
      " 7.08431034 5.89264358 5.30205996 0.22528578 5.75591413 8.80126198\n",
      " 0.18178115 6.35023124 3.22478898 4.62700277 2.20224928 9.70527011\n",
      " 7.92399682 2.39449365 1.08386274 9.02591598 8.41090766 7.60859376\n",
      " 5.66073797 2.44008026 9.02517436 3.7009884  1.81131523 2.14827008\n",
      " 7.56039104 2.03120849 7.33257629 5.91569164 1.79071863 8.65294348\n",
      " 7.60421311 2.57386233 8.17790792]\n",
      "Score [2.1000e+01 5.0000e+00 9.0000e+00 5.8000e+01 1.0500e+02 6.3000e+01\n",
      " 8.0000e+00 7.0000e+00 9.5000e+01 1.2800e+02 4.9000e+01 3.6000e+01\n",
      " 3.0000e+00 1.7000e+01 1.3000e+01 4.8000e+01 6.5000e+01 7.8000e+01\n",
      " 4.5000e+01 2.4000e+01 1.5000e+01 5.2000e+01 5.1000e+01 8.2430e+03\n",
      " 6.1000e+01 1.0350e+03 3.5000e+01 6.0000e+01 1.2000e+00 6.8000e+01\n",
      " 4.1000e+01 1.6000e+01 1.4000e+01 7.0300e+02 7.4000e+01 2.2000e+01\n",
      " 5.6000e+01 1.9800e+03 2.3000e+01 2.6000e+01 6.2000e+01 4.0000e+00\n",
      " 1.2000e+01 1.2500e+00 6.1600e+02 1.0000e+01 8.7000e+01 4.4000e+02\n",
      " 3.0000e+01 2.0000e+01 1.0400e+02 5.3000e+01 2.0000e+00 2.0400e+02\n",
      " 3.8000e+01 8.4000e+01 4.0000e+01 3.4000e+01 3.7200e+02 1.0000e+00\n",
      " 3.0000e+03 2.5000e+01 8.0300e+02 7.1000e+01 1.8000e+01 6.4000e+01\n",
      " 4.2000e+01 2.2890e+03 1.2000e+02 1.9800e+02 4.8600e+02 3.7000e+01\n",
      " 8.6000e+01 2.9000e+01 2.0800e+02 2.3270e+03 1.1000e+01 7.9000e+01\n",
      " 5.0000e+01 3.9000e+01 2.2500e+03 4.3000e+01 4.7640e+03 6.0000e+00\n",
      " 8.5000e+01 1.3100e+02 4.5552e+04 3.2000e+01 9.0000e+01 4.3200e+02\n",
      " 7.5000e+01 9.1000e+01 3.4500e+02]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for columns in df.columns:\n",
    "  df[columns].unique()\n",
    "  print(columns,df[columns].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "qIhHwaA1_fW0",
    "outputId": "e5369a3a-f6a8-4814-cafd-ff343e0fad6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.951158</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.534513</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5.918632</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8.226405</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077213</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Quantities  Number of Insignificant Quantities  Size  \\\n",
       "ID                                                                    \n",
       "371                     2                                   0     1   \n",
       "372                     2                                   0     1   \n",
       "373                     3                                   1     1   \n",
       "374                     2                                   0     1   \n",
       "375                     2                                   0     1   \n",
       "\n",
       "     Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                       \n",
       "371                     35                         108   \n",
       "372                     16                          53   \n",
       "373                     39                         140   \n",
       "374                     17                          59   \n",
       "375                     18                          74   \n",
       "\n",
       "     Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                    \n",
       "371                             3                    3            0   \n",
       "372                             2                    2            2   \n",
       "373                             3                    3            2   \n",
       "374                             3                    3            2   \n",
       "375                             2                    2            2   \n",
       "\n",
       "     Second Index  Difficulty  Score  \n",
       "ID                                    \n",
       "371            10    3.951158   21.0  \n",
       "372             5    6.534513    5.0  \n",
       "373            18    5.918632    9.0  \n",
       "374             7    8.226405   58.0  \n",
       "375             6    5.077213  105.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df['Size'] = df['Size'].map({\n",
    "    'Small': 0, \n",
    "    'Medium': 1,\n",
    "    'Big':2\n",
    "    })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqci1sqP_9M4"
   },
   "outputs": [],
   "source": [
    "y_pred = new_model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vOstfyY-ANzZ",
    "outputId": "9a41ab46-8dd3-4c28-f9d9-08e805df934e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.98804545e-01, 5.68068624e-02, 2.62115359e-01, 1.12025186e-01,\n",
       "        1.34785861e-01, 3.54622565e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.78880948e-01, 6.78227916e-02, 2.22530723e-01, 1.16902001e-01,\n",
       "        1.42927125e-01, 7.09363669e-02],\n",
       "       [3.99531841e-01, 5.62281720e-02, 2.64156967e-01, 1.11674793e-01,\n",
       "        1.34250611e-01, 3.41576859e-02],\n",
       "       [2.37844214e-01, 7.70101249e-02, 1.06722325e-01, 9.11699012e-02,\n",
       "        1.23153053e-01, 3.64100426e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.05918574e-01, 8.19770470e-02, 1.47315130e-01, 1.11404076e-01,\n",
       "        1.40116721e-01, 2.13268414e-01],\n",
       "       [3.99964899e-01, 5.58731034e-02, 2.65410721e-01, 1.11455694e-01,\n",
       "        1.33917481e-01, 3.33780423e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.73651803e-01, 1.31079359e-02, 4.89506602e-01, 5.90236969e-02,\n",
       "        6.43645003e-02, 3.45432083e-04],\n",
       "       [3.32680553e-01, 7.93566331e-02, 1.69645220e-01, 1.15495518e-01,\n",
       "        1.44081399e-01, 1.58740640e-01],\n",
       "       [3.41363698e-01, 7.80007914e-02, 1.77796662e-01, 1.16435103e-01,\n",
       "        1.44815877e-01, 1.41587853e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.49024266e-01, 7.65535906e-02, 1.85485378e-01, 1.17063567e-01,\n",
       "        1.45179987e-01, 1.26693130e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10117298e-01, 4.09870073e-02, 3.20919514e-01, 9.95960087e-02,\n",
       "        1.16888009e-01, 1.14922272e-02],\n",
       "       [3.85466754e-01, 6.49076849e-02, 2.33318672e-01, 1.15982905e-01,\n",
       "        1.41196027e-01, 5.91278747e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10135984e-01, 4.08802219e-02, 3.21353763e-01, 9.94920135e-02,\n",
       "        1.16744220e-01, 1.13937687e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.94803047e-01, 5.96674345e-02, 2.52031326e-01, 1.13631845e-01,\n",
       "        1.37288287e-01, 4.25780602e-02],\n",
       "       [3.34425747e-01, 7.91066065e-02, 1.71240702e-01, 1.15702048e-01,\n",
       "        1.44254103e-01, 1.55270904e-01],\n",
       "       [3.87913585e-01, 6.36814907e-02, 2.37753764e-01, 1.15507625e-01,\n",
       "        1.40367001e-01, 5.47765233e-02],\n",
       "       [3.97810549e-01, 5.75653091e-02, 2.59441763e-01, 1.12471692e-01,\n",
       "        1.35472849e-01, 3.72377858e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.88599604e-01, 6.33213371e-02, 2.39047900e-01, 1.15358859e-01,\n",
       "        1.40113026e-01, 5.35592884e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.06242818e-01, 2.83590071e-02, 3.79297227e-01, 8.51343647e-02,\n",
       "        9.74309146e-02, 3.53574799e-03],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.90267372e-01, 6.24129102e-02, 2.42297769e-01, 1.14965849e-01,\n",
       "        1.39452249e-01, 5.06039076e-02],\n",
       "       [2.67332315e-01, 8.09880421e-02, 1.22234978e-01, 1.01355329e-01,\n",
       "        1.31465986e-01, 2.96623379e-01],\n",
       "       [4.06523615e-01, 2.86868941e-02, 3.77546102e-01, 8.55721682e-02,\n",
       "        9.80062485e-02, 3.66498623e-03],\n",
       "       [3.86692286e-01, 1.68834832e-02, 4.54863042e-01, 6.68285489e-02,\n",
       "        7.40032792e-02, 7.29332969e-04],\n",
       "       [3.67536873e-01, 7.18476400e-02, 2.06711993e-01, 1.17578566e-01,\n",
       "        1.44645333e-01, 9.16796178e-02],\n",
       "       [4.09960866e-01, 3.52147706e-02, 3.45618844e-01, 9.35544521e-02,\n",
       "        1.08637020e-01, 7.01399799e-03],\n",
       "       [3.30984145e-01, 7.95893893e-02, 1.68113455e-01, 1.15286753e-01,\n",
       "        1.43902153e-01, 1.62124038e-01],\n",
       "       [2.83095688e-01, 8.25830996e-02, 1.30835488e-01, 1.06664971e-01,\n",
       "        1.35199144e-01, 2.61621684e-01],\n",
       "       [4.04420197e-01, 5.16192690e-02, 2.80560017e-01, 1.08594909e-01,\n",
       "        1.29656211e-01, 2.51494013e-02],\n",
       "       [4.07102495e-01, 4.81612459e-02, 2.93179035e-01, 1.05957173e-01,\n",
       "        1.25834405e-01, 1.97657272e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.86836648e-01, 1.69344041e-02, 4.54442173e-01, 6.69259802e-02,\n",
       "        7.41248876e-02, 7.35904265e-04],\n",
       "       [3.83827657e-01, 6.56822547e-02, 2.30489925e-01, 1.16257213e-01,\n",
       "        1.41690210e-01, 6.20526373e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.09166753e-01, 4.42613810e-02, 3.07937324e-01, 1.02650210e-01,\n",
       "        1.21143758e-01, 1.48405097e-02],\n",
       "       [3.73158097e-01, 1.29903778e-02, 4.90713060e-01, 5.87598756e-02,\n",
       "        6.40422329e-02, 3.36441968e-04],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.76327157e-01, 6.88263252e-02, 2.18709186e-01, 1.17141753e-01,\n",
       "        1.43436015e-01, 7.55595639e-02],\n",
       "       [3.07038039e-01, 8.19084719e-02, 1.48181275e-01, 1.11605719e-01,\n",
       "        1.40326127e-01, 2.10940316e-01],\n",
       "       [3.77191454e-01, 6.84937909e-02, 2.19982952e-01, 1.17067054e-01,\n",
       "        1.43272758e-01, 7.39920586e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.92364293e-01, 1.91029236e-02, 4.37436700e-01, 7.09123686e-02,\n",
       "        7.91282207e-02, 1.05542596e-03],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.84641647e-01, 1.61860418e-02, 4.60736990e-01, 6.54749498e-02,\n",
       "        7.23169968e-02, 6.43337844e-04],\n",
       "       [2.16422096e-01, 1.04355568e-03, 7.53051281e-01, 1.51293436e-02,\n",
       "        1.43534485e-02, 3.10988412e-07],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.97236437e-01, 5.79877868e-02, 2.57953107e-01, 1.12714089e-01,\n",
       "        1.35848254e-01, 3.82603519e-02],\n",
       "       [3.00320864e-01, 4.03468031e-03, 6.31045640e-01, 3.19822915e-02,\n",
       "        3.26043777e-02, 1.21659432e-05],\n",
       "       [3.81281555e-01, 6.68187067e-02, 2.26293221e-01, 1.16621137e-01,\n",
       "        1.42371431e-01, 6.66140243e-02],\n",
       "       [3.28198284e-01, 6.19299943e-03, 5.83427548e-01, 4.01854403e-02,\n",
       "        4.19555455e-02, 4.02232799e-05],\n",
       "       [3.94767940e-01, 5.96904755e-02, 2.51949996e-01, 1.13643892e-01,\n",
       "        1.37307420e-01, 4.26402241e-02],\n",
       "       [3.27833593e-01, 7.99955353e-02, 1.65316433e-01, 1.14878863e-01,\n",
       "        1.43540546e-01, 1.68435082e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.28113168e-01, 7.99608231e-02, 1.65562198e-01, 1.14916086e-01,\n",
       "        1.43574089e-01, 1.67873636e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.01506275e-01, 2.41455026e-02, 4.03426051e-01, 7.91422203e-02,\n",
       "        8.96303803e-02, 2.14958936e-03],\n",
       "       [4.10346746e-01, 3.82965915e-02, 3.32102925e-01, 9.68885422e-02,\n",
       "        1.13165520e-01, 9.19964816e-03],\n",
       "       [3.20896417e-01, 8.07759836e-02, 1.59360170e-01, 1.13893598e-01,\n",
       "        1.42620370e-01, 1.82453394e-01],\n",
       "       [3.86700064e-01, 1.68862119e-02, 4.54840511e-01, 6.68337718e-02,\n",
       "        7.40097985e-02, 7.29683670e-04],\n",
       "       [2.44394735e-01, 7.79976696e-02, 1.10110603e-01, 9.34582129e-02,\n",
       "        1.25137582e-01, 3.48901272e-01],\n",
       "       [4.05339271e-01, 5.05468510e-02, 2.84436256e-01, 1.07806474e-01,\n",
       "        1.28504902e-01, 2.33662855e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.88034970e-01, 6.36183396e-02, 2.37980962e-01, 1.15481846e-01,\n",
       "        1.40322804e-01, 5.45611605e-02],\n",
       "       [3.77372503e-01, 1.40446294e-02, 4.80202973e-01, 6.10767268e-02,\n",
       "        6.68801591e-02, 4.22983809e-04],\n",
       "       [3.37580293e-01, 7.17136962e-03, 5.66105783e-01, 4.33959290e-02,\n",
       "        4.56857756e-02, 6.08705413e-05],\n",
       "       [3.68316114e-01, 7.16039091e-02, 2.07713470e-01, 1.17561184e-01,\n",
       "        1.44567952e-01, 9.02373418e-02],\n",
       "       [3.56084943e-01, 9.66583285e-03, 5.29261947e-01, 5.06242365e-02,\n",
       "        5.42202890e-02, 1.42724617e-04],\n",
       "       [3.12252432e-01, 8.15453157e-02, 1.52284935e-01, 1.12513080e-01,\n",
       "        1.41255826e-01, 2.00148419e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.41388464e-01, 7.79965222e-02, 1.77820683e-01, 1.16437465e-01,\n",
       "        1.44817516e-01, 1.41539425e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.89313996e-01, 6.29380643e-02, 2.40421399e-01, 1.15196101e-01,\n",
       "        1.39837757e-01, 5.22927120e-02],\n",
       "       [3.85494351e-01, 1.64702553e-02, 4.58318055e-01, 6.60309047e-02,\n",
       "        7.30088502e-02, 6.77487056e-04],\n",
       "       [4.00147736e-01, 5.57207838e-02, 2.65948921e-01, 1.11360744e-01,\n",
       "        1.33773476e-01, 3.30483019e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.98175865e-01, 5.72907217e-02, 2.60409504e-01, 1.12311713e-01,\n",
       "        1.35226056e-01, 3.65861803e-02],\n",
       "       [3.32241148e-01, 7.94178918e-02, 1.69246674e-01, 1.15442216e-01,\n",
       "        1.44036040e-01, 1.59616053e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10116822e-01, 3.59400958e-02, 3.42362016e-01, 9.43624228e-02,\n",
       "        1.09729223e-01, 7.48937437e-03],\n",
       "       [4.05324250e-01, 5.05651273e-02, 2.84369916e-01, 1.07820131e-01,\n",
       "        1.28524750e-01, 2.33957879e-02],\n",
       "       [4.10006076e-01, 3.54064032e-02, 3.44753593e-01, 9.37693417e-02,\n",
       "        1.08927198e-01, 7.13736052e-03],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10324425e-01, 3.92406099e-02, 3.28119278e-01, 9.78594795e-02,\n",
       "        1.14495516e-01, 9.96062625e-03],\n",
       "       [4.09759432e-01, 3.44772749e-02, 3.48982453e-01, 9.27177295e-02,\n",
       "        1.07509300e-01, 6.55381894e-03],\n",
       "       [2.13379547e-01, 9.88960732e-04, 7.57070303e-01, 1.46760959e-02,\n",
       "        1.38848322e-02, 2.69517500e-07],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.32559645e-01, 7.93735608e-02, 1.69535428e-01, 1.15480915e-01,\n",
       "        1.44068986e-01, 1.58981472e-01],\n",
       "       [4.09851968e-01, 4.21908274e-02, 3.16073775e-01, 1.00748986e-01,\n",
       "        1.18487015e-01, 1.26475291e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.08994466e-01, 3.24940830e-02, 3.58308434e-01, 9.03889909e-02,\n",
       "        1.04387902e-01, 5.42609673e-03],\n",
       "       [3.91160816e-01, 1.85906217e-02, 4.41301793e-01, 6.99980929e-02,\n",
       "        7.79759437e-02, 9.72679409e-04],\n",
       "       [4.03836995e-01, 5.22555821e-02, 2.78273255e-01, 1.09050050e-01,\n",
       "        1.30324826e-01, 2.62592155e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.46721590e-01, 7.70153180e-02, 1.83119431e-01, 1.16896287e-01,\n",
       "        1.45101115e-01, 1.31146282e-01],\n",
       "       [3.75509888e-01, 1.35641089e-02, 4.84909028e-01, 6.00342229e-02,\n",
       "        6.56009540e-02, 3.81865422e-04],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10026163e-01, 3.54955867e-02, 3.44352126e-01, 9.38690081e-02,\n",
       "        1.09061837e-01, 7.19531812e-03],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.93908560e-01, 6.02449775e-02, 2.49991536e-01, 1.13930002e-01,\n",
       "        1.37763530e-01, 4.41614501e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.66054624e-01, 7.22995475e-02, 2.04836071e-01, 1.17601462e-01,\n",
       "        1.44778222e-01, 9.44300368e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.01391298e-01, 2.40636617e-02, 4.03928190e-01, 7.90185556e-02,\n",
       "        8.94708186e-02, 2.12731189e-03],\n",
       "       [4.02280539e-01, 5.38202152e-02, 2.72685498e-01, 1.10128842e-01,\n",
       "        1.31922618e-01, 2.91622747e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10304576e-01, 3.73540446e-02, 3.36150140e-01, 9.58959609e-02,\n",
       "        1.11811288e-01, 8.48409534e-03],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.02459830e-01, 5.36486730e-02, 2.73295999e-01, 1.10013388e-01,\n",
       "        1.31750658e-01, 2.88314521e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.78513134e-01, 8.21609274e-02, 1.28310144e-01, 1.05132267e-01,\n",
       "        1.34169832e-01, 2.71713614e-01],\n",
       "       [3.56673896e-01, 7.48386160e-02, 1.93732977e-01, 1.17470130e-01,\n",
       "        1.45231619e-01, 1.12052664e-01],\n",
       "       [4.09924448e-01, 3.50686982e-02, 3.46280903e-01, 9.33899507e-02,\n",
       "        1.08415045e-01, 6.92101894e-03],\n",
       "       [3.95075947e-01, 2.03589853e-02, 4.28316981e-01, 7.30878934e-02,\n",
       "        8.18814784e-02, 1.27877248e-03],\n",
       "       [4.01356667e-01, 5.46734408e-02, 2.69655645e-01, 1.10692658e-01,\n",
       "        1.32765859e-01, 3.08557618e-02],\n",
       "       [4.09234285e-01, 4.40903082e-02, 3.08600843e-01, 1.02497004e-01,\n",
       "        1.20928697e-01, 1.46489479e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.82251233e-01, 6.63949996e-02, 2.27864966e-01, 1.16490982e-01,\n",
       "        1.42123729e-01, 6.48741126e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.05311346e-01, 2.73570158e-02, 3.84752840e-01, 8.37722272e-02,\n",
       "        9.56457257e-02, 3.16101103e-03],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [3.99470091e-01, 2.27870885e-02, 4.11952645e-01, 7.70507529e-02,\n",
       "        8.69388953e-02, 1.80051511e-03],\n",
       "       [4.02762473e-01, 5.33543043e-02, 2.74344772e-01, 1.09813645e-01,\n",
       "        1.31453738e-01, 2.82710847e-02],\n",
       "       [3.91786903e-01, 6.15412407e-02, 2.45399907e-01, 1.14565544e-01,\n",
       "        1.38791725e-01, 4.79146317e-02],\n",
       "       [3.77548367e-01, 6.83543831e-02, 2.20514700e-01, 1.17034324e-01,\n",
       "        1.43202722e-01, 7.33455941e-02],\n",
       "       [3.95622611e-01, 5.91203645e-02, 2.53961265e-01, 1.13341071e-01,\n",
       "        1.36828586e-01, 4.11259830e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [4.10161197e-01, 4.07290012e-02, 3.21970075e-01, 9.93442461e-02,\n",
       "        1.16540000e-01, 1.12554329e-02],\n",
       "       [3.75550658e-01, 6.91191927e-02, 2.17580870e-01, 1.17203526e-01,\n",
       "        1.43575236e-01, 7.69705549e-02],\n",
       "       [3.90182257e-01, 6.24604411e-02, 2.42128119e-01, 1.14987023e-01,\n",
       "        1.39487505e-01, 5.07545955e-02],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [2.35684156e-01, 7.66869783e-02, 1.05628870e-01, 9.03669149e-02,\n",
       "        1.22428499e-01, 3.69204551e-01],\n",
       "       [1.52790219e-01, 2.95842648e-04, 8.33037674e-01, 7.34240841e-03,\n",
       "        6.53381227e-03, 1.12282761e-08],\n",
       "       [4.00427967e-01, 5.54843657e-02, 2.66784638e-01, 1.11212276e-01,\n",
       "        1.33548707e-01, 3.25420536e-02],\n",
       "       [4.02254134e-01, 5.38453162e-02, 2.72596210e-01, 1.10145673e-01,\n",
       "        1.31947696e-01, 2.92109419e-02],\n",
       "       [3.66632730e-01, 1.15645025e-02, 5.06115794e-01, 5.54400794e-02,\n",
       "        6.00072034e-02, 2.39701898e-04]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ipfU_cVbAP8x",
    "outputId": "eb1da323-4304-4299-a914-75bd783d5470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YH0_2kRSAhdU",
    "outputId": "81b32e9a-f8f9-4c4b-9b71-baabca15109b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNs8zuKZAl1m"
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(y_pred)):\n",
    "  temp = y_pred[i,:]\n",
    "  ind = np.argmax(temp)\n",
    "  list1.append(ind)\n",
    "y_test = np.array(list1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2S_X7BASDKle",
    "outputId": "858d0856-bf94-4e5b-e182-28daf4dca0e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 5, 0, 0, 5, 5, 0, 0, 5, 5, 5, 2, 0, 0, 5, 0, 5, 0, 0, 5, 0,\n",
       "       5, 0, 0, 0, 0, 5, 5, 0, 5, 0, 5, 0, 5, 0, 2, 0, 0, 0, 0, 0, 0, 5,\n",
       "       5, 2, 0, 5, 0, 2, 5, 0, 0, 0, 5, 2, 5, 2, 2, 5, 0, 2, 0, 2, 0, 0,\n",
       "       5, 0, 5, 2, 0, 0, 2, 5, 0, 5, 0, 2, 2, 0, 2, 0, 5, 0, 5, 0, 2, 0,\n",
       "       5, 5, 0, 0, 5, 0, 0, 0, 5, 5, 0, 0, 2, 5, 0, 0, 5, 0, 2, 0, 5, 5,\n",
       "       0, 2, 5, 5, 0, 5, 0, 5, 0, 5, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 0, 2,\n",
       "       0, 0, 5, 5, 5, 0, 5, 0, 5, 5, 5, 2, 0, 0, 0, 0, 5, 5, 0, 0, 0, 5,\n",
       "       5, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "TdNXTs9qDMIm",
    "outputId": "c5acda37-a0a9-4c73-fdcb-1fa454144a77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.951158</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.534513</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5.918632</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8.226405</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077213</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1.790719</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8.652943</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.604213</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.573862</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>8.177908</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Quantities  Number of Insignificant Quantities  Size  \\\n",
       "ID                                                                    \n",
       "371                     2                                   0     1   \n",
       "372                     2                                   0     1   \n",
       "373                     3                                   1     1   \n",
       "374                     2                                   0     1   \n",
       "375                     2                                   0     1   \n",
       "..                    ...                                 ...   ...   \n",
       "525                     2                                   0     0   \n",
       "526                     2                                   0     1   \n",
       "527                     2                                   0     1   \n",
       "528                     2                                   0     1   \n",
       "529                     2                                   0     2   \n",
       "\n",
       "     Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                       \n",
       "371                     35                         108   \n",
       "372                     16                          53   \n",
       "373                     39                         140   \n",
       "374                     17                          59   \n",
       "375                     18                          74   \n",
       "..                     ...                         ...   \n",
       "525                     35                         132   \n",
       "526                     31                         110   \n",
       "527                     19                          65   \n",
       "528                     21                          76   \n",
       "529                     34                         115   \n",
       "\n",
       "     Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                    \n",
       "371                             3                    3            0   \n",
       "372                             2                    2            2   \n",
       "373                             3                    3            2   \n",
       "374                             3                    3            2   \n",
       "375                             2                    2            2   \n",
       "..                            ...                  ...          ...   \n",
       "525                             3                    3           15   \n",
       "526                             2                    2           11   \n",
       "527                             3                    3            2   \n",
       "528                             3                    3            3   \n",
       "529                             3                    3            5   \n",
       "\n",
       "     Second Index  Difficulty  Score  \n",
       "ID                                    \n",
       "371            10    3.951158   21.0  \n",
       "372             5    6.534513    5.0  \n",
       "373            18    5.918632    9.0  \n",
       "374             7    8.226405   58.0  \n",
       "375             6    5.077213  105.0  \n",
       "..            ...         ...    ...  \n",
       "525            20    1.790719   11.0  \n",
       "526            14    8.652943  432.0  \n",
       "527             8    7.604213   75.0  \n",
       "528             8    2.573862   91.0  \n",
       "529            21    8.177908  345.0  \n",
       "\n",
       "[159 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCMvjoPWDqCn"
   },
   "outputs": [],
   "source": [
    "df_2 = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nin8PJLOG8H-"
   },
   "outputs": [],
   "source": [
    "\n",
    "col_name = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65qWDSiwE3Nv"
   },
   "outputs": [],
   "source": [
    "df_2[\"Class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "id": "vpNb_WVwFeXw",
    "outputId": "689ca56e-66b3-48d8-af68-54e5be8495b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.951158</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.534513</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5.918632</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8.226405</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077213</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1.790719</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8.652943</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.604213</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.573862</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>8.177908</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Quantities  Number of Insignificant Quantities  Size  \\\n",
       "ID                                                                    \n",
       "371                     2                                   0     1   \n",
       "372                     2                                   0     1   \n",
       "373                     3                                   1     1   \n",
       "374                     2                                   0     1   \n",
       "375                     2                                   0     1   \n",
       "..                    ...                                 ...   ...   \n",
       "525                     2                                   0     0   \n",
       "526                     2                                   0     1   \n",
       "527                     2                                   0     1   \n",
       "528                     2                                   0     1   \n",
       "529                     2                                   0     2   \n",
       "\n",
       "     Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                       \n",
       "371                     35                         108   \n",
       "372                     16                          53   \n",
       "373                     39                         140   \n",
       "374                     17                          59   \n",
       "375                     18                          74   \n",
       "..                     ...                         ...   \n",
       "525                     35                         132   \n",
       "526                     31                         110   \n",
       "527                     19                          65   \n",
       "528                     21                          76   \n",
       "529                     34                         115   \n",
       "\n",
       "     Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                    \n",
       "371                             3                    3            0   \n",
       "372                             2                    2            2   \n",
       "373                             3                    3            2   \n",
       "374                             3                    3            2   \n",
       "375                             2                    2            2   \n",
       "..                            ...                  ...          ...   \n",
       "525                             3                    3           15   \n",
       "526                             2                    2           11   \n",
       "527                             3                    3            2   \n",
       "528                             3                    3            3   \n",
       "529                             3                    3            5   \n",
       "\n",
       "     Second Index  Difficulty  Score  Class  \n",
       "ID                                           \n",
       "371            10    3.951158   21.0      0  \n",
       "372             5    6.534513    5.0      0  \n",
       "373            18    5.918632    9.0      0  \n",
       "374             7    8.226405   58.0      0  \n",
       "375             6    5.077213  105.0      0  \n",
       "..            ...         ...    ...    ...  \n",
       "525            20    1.790719   11.0      0  \n",
       "526            14    8.652943  432.0      0  \n",
       "527             8    7.604213   75.0      0  \n",
       "528             8    2.573862   91.0      0  \n",
       "529            21    8.177908  345.0      0  \n",
       "\n",
       "[159 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fve7aA3gFf3D"
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "  df_2.iloc[i,11] = y_test[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "id": "r4-HCylSGIml",
    "outputId": "1b9181e3-6ce2-4b61-c9c8-2e1b43f73227"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Quantities</th>\n",
       "      <th>Number of Insignificant Quantities</th>\n",
       "      <th>Size</th>\n",
       "      <th>Total Number of Words</th>\n",
       "      <th>Total Number of Characters</th>\n",
       "      <th>Number of Special Characters</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>First Index</th>\n",
       "      <th>Second Index</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Score</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.951158</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.534513</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5.918632</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8.226405</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077213</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1.790719</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8.652943</td>\n",
       "      <td>432.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.604213</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.573862</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>8.177908</td>\n",
       "      <td>345.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of Quantities  Number of Insignificant Quantities  Size  \\\n",
       "ID                                                                    \n",
       "371                     2                                   0     1   \n",
       "372                     2                                   0     1   \n",
       "373                     3                                   1     1   \n",
       "374                     2                                   0     1   \n",
       "375                     2                                   0     1   \n",
       "..                    ...                                 ...   ...   \n",
       "525                     2                                   0     0   \n",
       "526                     2                                   0     1   \n",
       "527                     2                                   0     1   \n",
       "528                     2                                   0     1   \n",
       "529                     2                                   0     2   \n",
       "\n",
       "     Total Number of Words  Total Number of Characters  \\\n",
       "ID                                                       \n",
       "371                     35                         108   \n",
       "372                     16                          53   \n",
       "373                     39                         140   \n",
       "374                     17                          59   \n",
       "375                     18                          74   \n",
       "..                     ...                         ...   \n",
       "525                     35                         132   \n",
       "526                     31                         110   \n",
       "527                     19                          65   \n",
       "528                     21                          76   \n",
       "529                     34                         115   \n",
       "\n",
       "     Number of Special Characters  Number of Sentences  First Index  \\\n",
       "ID                                                                    \n",
       "371                             3                    3            0   \n",
       "372                             2                    2            2   \n",
       "373                             3                    3            2   \n",
       "374                             3                    3            2   \n",
       "375                             2                    2            2   \n",
       "..                            ...                  ...          ...   \n",
       "525                             3                    3           15   \n",
       "526                             2                    2           11   \n",
       "527                             3                    3            2   \n",
       "528                             3                    3            3   \n",
       "529                             3                    3            5   \n",
       "\n",
       "     Second Index  Difficulty  Score  Class  \n",
       "ID                                           \n",
       "371            10    3.951158   21.0      0  \n",
       "372             5    6.534513    5.0      5  \n",
       "373            18    5.918632    9.0      5  \n",
       "374             7    8.226405   58.0      0  \n",
       "375             6    5.077213  105.0      0  \n",
       "..            ...         ...    ...    ...  \n",
       "525            20    1.790719   11.0      5  \n",
       "526            14    8.652943  432.0      2  \n",
       "527             8    7.604213   75.0      0  \n",
       "528             8    2.573862   91.0      0  \n",
       "529            21    8.177908  345.0      2  \n",
       "\n",
       "[159 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUuUotPHGKJ8"
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.drop(columns=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1Wn6cV7GzYm"
   },
   "outputs": [],
   "source": [
    "df_2.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "3DnCgURgIDyU",
    "outputId": "d71ddd0e-a1df-4352-d616-5b7618319be1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class\n",
       "ID        \n",
       "371      0\n",
       "372      5\n",
       "373      5\n",
       "374      0\n",
       "375      0\n",
       "..     ...\n",
       "525      5\n",
       "526      2\n",
       "527      0\n",
       "528      0\n",
       "529      2\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v4bgI0ViIczu",
    "outputId": "4278fb50-ed36-4094-e7a4-2b0632e8dc35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a download=\"data.csv\" href=\"data:text/csv;base64,Q2xhc3MKMAo1CjUKMAowCjUKNQowCjAKNQo1CjUKMgowCjAKNQowCjUKMAowCjUKMAo1CjAKMAowCjAKNQo1CjAKNQowCjUKMAo1CjAKMgowCjAKMAowCjAKMAo1CjUKMgowCjUKMAoyCjUKMAowCjAKNQoyCjUKMgoyCjUKMAoyCjAKMgowCjAKNQowCjUKMgowCjAKMgo1CjAKNQowCjIKMgowCjIKMAo1CjAKNQowCjIKMAo1CjUKMAowCjUKMAowCjAKNQo1CjAKMAoyCjUKMAowCjUKMAoyCjAKNQo1CjAKMgo1CjUKMAo1CjAKNQowCjUKMgowCjUKMAo1CjUKMAo1CjAKMAowCjIKMAowCjUKNQo1CjAKNQowCjUKNQo1CjIKMAowCjAKMAo1CjUKMAowCjAKNQo1CjIKMAowCjIK\"target=\"_blank\">Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):\n",
    "  csv = df.to_csv(index=False)\n",
    "  b64 = base64.b64encode(csv.encode())\n",
    "  payload = b64.decode()\n",
    "  html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\"target=\"_blank\">{title}</a>'\n",
    "  html = html.format(payload=payload,title=title,filename=filename)\n",
    "  return HTML(html)\n",
    "create_download_link(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTxCJdno1W9q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2017A8PS1926G",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
